{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5ea718",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Annotator Indo-Javanese NLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1e1c2c",
   "metadata": {},
   "source": [
    "Welcome to Jupyter Notebook file for Indo-Javanese NLI dataset annotation!\n",
    "\n",
    "I would like to offer my gratitute for you all to contribute to my postgrad's thesis.\n",
    "\n",
    "NLI is an abbreviation of \"Natural Language Inference\", a subset study of NLP. What NLI do? Well, an NLI model is an AI model to help AI better understand semantic relation between 2 kind of sentences: a premise sentence, and hypothesis sentence. Semantic relation between the two sentences state whether a hypothesis sentence is **true**, **false**, or **can't be decided** based on the information on the premise. \n",
    "\n",
    "- If a hypothesis sentence is **true** based on the information on the premise, then the label is **entailment**, symbolized by zero (0) on the label column.\n",
    "- If the information on the hypothesis sentence **can't be decided** based on the information on the premise, then the label is **neutral**, symbolized by one (1) on the label column.\n",
    "- If a hypothesis sentence is **false** based on the information on the premise, then the label is **contradict**, symbolized by two (2) on the label column.\n",
    "\n",
    "Your task as an annotator is simple!\n",
    "\n",
    "I will provide the NLI data translated from Indonesian language to Javanese language using 3 different API:\n",
    "- Mongosilakan.net,\n",
    "- Google Translate, and\n",
    "- ChatGPT 3.5\n",
    "\n",
    "Here's what you will do:\n",
    "- 3 different translated hypothesis data will be served in random order/random column in each row.\n",
    "- You will rank 1-5 (5 being the best, and 1 being the lowest) as the quality of each translation.\n",
    "- Every translation (all of column \"1\", column \"2\", and column \"3\") must be ranked.\n",
    "- Pay attention whether each translated data **changes** the semantic relation with its premise sentence. I will also provide the premise sentence in Indonesian. So, pay closely whether the semantic relation change, for example, from entailment (symbolized by zero on the \"label\" column) to contradict.\n",
    "- I will provide you with the annotation protocol guide.\n",
    "\n",
    "\n",
    "If you have any other question, please do contact me via WhatsApp Group or send me an email to 23521059@std.stei.itb.ac.id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1dfcfa",
   "metadata": {},
   "source": [
    "## Import Libraries and Prepare the File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1855bb45",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a90e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86a91cf",
   "metadata": {},
   "source": [
    "Checking csv file\n",
    "\n",
    "If you run this Jupyter Notebook file locally, you could change the ```os.getcwd()``` in the cell below to the path of this Jupyter Notebook file. The local path for ```current_directory``` variable should be in the form of:\n",
    "\n",
    "```\"D:\\\\Folder 1\\\\Subfolder 1\\\\Subfolder 2\\\\Subfolder 3\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0910a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "filename = \"test-for_annotator.csv\"\n",
    "\n",
    "current_directory = current_directory.replace(\"\\\\\", \"/\")\n",
    "full_path_to_filename = os.path.join(current_directory, filename)\n",
    "\n",
    "if (os.path.exists(full_path_to_filename)):\n",
    "    print(\"File checked.\")\n",
    "else:\n",
    "    print(f\"File {filename} not exist!\")\n",
    "    print(f\"Please upload {filename} to the same directory in Google Colab or place it in the same directory as this Jupyter Notebook file.\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b44d86",
   "metadata": {},
   "source": [
    "Load and View the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_testing = pd.read_csv(full_path_to_filename, sep=\"\\t\")\n",
    "df_data_testing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25e8e4b",
   "metadata": {},
   "source": [
    "## Annotate the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb1eef5",
   "metadata": {},
   "source": [
    "The function below is used to help you annotate the data. Please don't change this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c243ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(the_column, the_row):\n",
    "    print(f\"Annotation for the {the_column} column in the row {str(the_row+1)}\")\n",
    "    x = input(f\"Please put your mark (1-5) here for column {the_column}:\")\n",
    "    \n",
    "    try:\n",
    "        if(int(x) > 5 or int(x) < 1):\n",
    "            print(\"Rank out of range!\")\n",
    "            print(\"Please input your mark from 1 to 5 (1 and 5 included, 5 being the best).\")\n",
    "        else:\n",
    "            df_data_testing.loc[the_row, the_column] = int(x)\n",
    "    except Exception as e:\n",
    "        print(\"Error!\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da15df76",
   "metadata": {},
   "source": [
    "**Checkpoint**\n",
    "\n",
    "The code below is used to view the data for a given column. You can change the ```row``` variable value after you have already finished viewing and giving rank to all 3 columns in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 0 # you can change this value after you have already giving rank for all 3 columns in this row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Kalimat hipotesis dalam bahasa Indonesia pada row {str(row+1)}:\")\n",
    "print(df_data_testing[\"hypothesis\"][row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c34d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_data_testing[\"1\"][row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90713b9c",
   "metadata": {},
   "source": [
    "After filling in the rank, please press Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a85079",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate(\"rank_1\", row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c08d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_data_testing[\"2\"][row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee5f81e",
   "metadata": {},
   "source": [
    "After filling in the rank, please press Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42354a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate(\"rank_2\", row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae06ce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_data_testing[\"3\"][row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836e78b6",
   "metadata": {},
   "source": [
    "After filling in the rank, please press Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc9cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate(\"rank_3\", row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98f90f3",
   "metadata": {},
   "source": [
    "After you have done ranking all the 3 columns, you can add the ```row``` variable above by 1 to continue annotating, or you could save the annotated data now to continue annotate it later. Should you decide to continue later, please make sure to save the row value you're currently working at."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07927d77",
   "metadata": {},
   "source": [
    "## Save the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaeea27",
   "metadata": {},
   "source": [
    "Before saving, please make sure you save/remember the last ```row``` variable value you're currently working at. Then, run this code below to save the annotated data. \n",
    "\n",
    "\n",
    "**ACHTUNG! URGENT!**\n",
    "\n",
    "DO NOT forget to download the data after you run the code below if you're using cloud service such as Google Colab, etc. If you're using local Jupyter Notebook, it's save to close the browser/tab after saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c1d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_testing.to_csv(full_path_to_filename, sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-torch",
   "language": "python",
   "name": "my-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
