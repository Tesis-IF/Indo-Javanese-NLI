{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22ce6390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 09:26:02.688216: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-04 09:26:03.645601: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-04 09:26:03.645710: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-04 09:26:03.645721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# set a seed value\n",
    "torch.manual_seed(555)\n",
    "\n",
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e91338",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = 'bert-large-uncased'\n",
    "L_RATE = 1e-5\n",
    "MAX_LEN = 512\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 2\n",
    "NUM_CORES = os.cpu_count() - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4ec26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5471c5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dddefd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"dataset/indo_java_nli_training.csv\", sep='\\t')\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True) #shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9528ad07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Selulit sendiri merupakan kondisi munculnya ga...</td>\n",
       "      <td>Selulit yaiku kondhisi munculna garis halu ing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Banpres adalah sebuah desa yang terletak di ke...</td>\n",
       "      <td>Sumatera Selatan ana desa sing ana jenengé Ban...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Itulah sebabnya masakan Indonesia memiliki cit...</td>\n",
       "      <td>Indonesia duwe rempah-rempah sing aneka rupa.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Selain itu, ia juga memiliki andil dari rumah ...</td>\n",
       "      <td>Sing konangan ngrangsang ing panggung gedhong.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Moonlight Resonance\" adalah serial drama HDTV...</td>\n",
       "      <td>\"Serial drama \"Moonlight Resonance\" tayang nga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  Selulit sendiri merupakan kondisi munculnya ga...   \n",
       "1  Banpres adalah sebuah desa yang terletak di ke...   \n",
       "2  Itulah sebabnya masakan Indonesia memiliki cit...   \n",
       "3  Selain itu, ia juga memiliki andil dari rumah ...   \n",
       "4  \"Moonlight Resonance\" adalah serial drama HDTV...   \n",
       "\n",
       "                                          hypothesis  label  \n",
       "0  Selulit yaiku kondhisi munculna garis halu ing...      0  \n",
       "1  Sumatera Selatan ana desa sing ana jenengé Ban...      0  \n",
       "2      Indonesia duwe rempah-rempah sing aneka rupa.      0  \n",
       "3     Sing konangan ngrangsang ing panggung gedhong.      0  \n",
       "4  \"Serial drama \"Moonlight Resonance\" tayang nga...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_new = pd.DataFrame()\n",
    "df_train_new[\"premise\"] = df_train[\"premise\"]\n",
    "df_train_new[\"hypothesis\"] = df_train[\"jv_hypothesis\"]\n",
    "df_train_new[\"label\"] = df_train[\"label\"]\n",
    "df_train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a6bbda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv(\"dataset/indo_java_nli_validation.csv\", sep='\\t')\n",
    "df_valid = df_valid.sample(frac=1).reset_index(drop=True) #shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f6e9cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janji tatanan Angkatan Laut baru untuk mengama...</td>\n",
       "      <td>Tatanan Angkatan Laut anyar ora pernah ngandhu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kompleks Candi Dieng ini memiliki usia yang su...</td>\n",
       "      <td>Pembangunan kompleks Candi Dieng rampung ing a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple membeli NeXT pada tanggal 20 Desember 19...</td>\n",
       "      <td>Apple ndhuwur ing NexT.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Usai proses mentoring, imbuhnya, satu dari emp...</td>\n",
       "      <td>Foster ora bakal nglakoni konser.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Namun Polri bersedia membantu bila Biro Invest...</td>\n",
       "      <td>Polri saiki ngunakake FBI.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  Janji tatanan Angkatan Laut baru untuk mengama...   \n",
       "1  Kompleks Candi Dieng ini memiliki usia yang su...   \n",
       "2  Apple membeli NeXT pada tanggal 20 Desember 19...   \n",
       "3  Usai proses mentoring, imbuhnya, satu dari emp...   \n",
       "4  Namun Polri bersedia membantu bila Biro Invest...   \n",
       "\n",
       "                                          hypothesis  label  \n",
       "0  Tatanan Angkatan Laut anyar ora pernah ngandhu...      2  \n",
       "1  Pembangunan kompleks Candi Dieng rampung ing a...      1  \n",
       "2                            Apple ndhuwur ing NexT.      0  \n",
       "3                  Foster ora bakal nglakoni konser.      2  \n",
       "4                         Polri saiki ngunakake FBI.      2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_new = pd.DataFrame()\n",
    "df_valid_new[\"premise\"] = df_valid[\"premise\"]\n",
    "df_valid_new[\"hypothesis\"] = df_valid[\"jv_hypothesis\"]\n",
    "df_valid_new[\"label\"] = df_valid[\"label\"]\n",
    "df_valid_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2192e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"dataset/indo_java_nli_testing.csv\", sep='\\t')\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True) #shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17be87e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beragam penduduk asli mendiami Alaska selama r...</td>\n",
       "      <td>Wong asli sing manggon ing Alaska ora beda-beda.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tercatat 37 dokter di Italia meninggal akibat ...</td>\n",
       "      <td>Luwih saka enem ewu tenaga medis uga kena infe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Seperti ada kerusakan di bagian belakang,\" ka...</td>\n",
       "      <td>Iku bener ana karusakan ing mburi kaya Sean ng...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unsur busana lain yang sangat penting adalah u...</td>\n",
       "      <td>Upuh ulen-ulen iku dudu unsur sing penting ban...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kendati vegetasi laut hanya memiliki proporsi ...</td>\n",
       "      <td>Kemampuan kanggo nyimpen karbon saka vegetasi ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  Beragam penduduk asli mendiami Alaska selama r...   \n",
       "1  Tercatat 37 dokter di Italia meninggal akibat ...   \n",
       "2  \"Seperti ada kerusakan di bagian belakang,\" ka...   \n",
       "3  Unsur busana lain yang sangat penting adalah u...   \n",
       "4  Kendati vegetasi laut hanya memiliki proporsi ...   \n",
       "\n",
       "                                          hypothesis  label  \n",
       "0   Wong asli sing manggon ing Alaska ora beda-beda.      2  \n",
       "1  Luwih saka enem ewu tenaga medis uga kena infe...      0  \n",
       "2  Iku bener ana karusakan ing mburi kaya Sean ng...      1  \n",
       "3  Upuh ulen-ulen iku dudu unsur sing penting ban...      2  \n",
       "4  Kemampuan kanggo nyimpen karbon saka vegetasi ...      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_new = pd.DataFrame()\n",
    "df_test_new[\"premise\"] = df_test[\"premise\"]\n",
    "df_test_new[\"hypothesis\"] = df_test[\"jv_hypothesis\"]\n",
    "df_test_new[\"label\"] = df_test[\"label\"]\n",
    "df_test_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14033144",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cb6da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df_data = df\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sentence1 = self.df_data.loc[index, 'premise']\n",
    "        sentence2 = self.df_data.loc[index, 'hypothesis']\n",
    "        \n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sentence1,\n",
    "            sentence2,\n",
    "            add_special_tokens = True,\n",
    "            max_length = MAX_LEN,\n",
    "            truncation='longest_first',\n",
    "            padding = 'max_length',\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt'\n",
    "        )\n",
    "        \n",
    "        padded_token_list = encoded_dict['input_ids'][0]\n",
    "        att_mask = encoded_dict['attention_mask'][0]\n",
    "        \n",
    "        target = torch.tensor(self.df_data.loc[index, 'label'])\n",
    "        sample = {\"input_ids\": padded_token_list, \"attention_mask\": att_mask, \"label\": target}\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e03f5f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cmp = CompDataset(df_train_new)\n",
    "valid_data_cmp = CompDataset(df_valid_new)\n",
    "test_data_cmp = CompDataset(df_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b05c0eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah core: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Jumlah core: {str(NUM_CORES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9f7ffe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(MODEL_TYPE, num_labels=3)\n",
    "\n",
    "# Send the model to the device.\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1993be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average='micro')\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average='micro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average='weighted')\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa75fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"saved_models/Indo-Javanese-NLI/BaselineModels/bert-large-epoch10\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    seed=101,\n",
    "    learning_rate=L_RATE,\n",
    "    report_to=\"none\" #\"azure-ml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a07d2902",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data_cmp,\n",
    "    eval_dataset=valid_data_cmp,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2501f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tf_gpu_research/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='25830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   34/25830 00:28 < 6:27:17, 1.11 it/s, Epoch 0.01/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train pre-trained model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b15daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = trainer.predict(test_data_cmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9abe6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing metrics:\", prediction[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba30da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocess raw predictions\n",
    "y_pred = np.argmax(prediction[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a048a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_label(the_label):\n",
    "    str_label = \"\"\n",
    "    if str(the_label) == \"0\":\n",
    "        str_label = \"entail\"\n",
    "    elif str(the_label) == \"1\":\n",
    "        str_label = \"neutral\"\n",
    "    else:\n",
    "        str_label = \"contradict\"\n",
    "    return str_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035aea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_test_new.iterrows():\n",
    "    ground_truth = prediction[1][idx]\n",
    "    if y_pred[idx] != ground_truth:\n",
    "        print(\"==========================================================================================\")\n",
    "        print(f\"Premis: {row['premise']}\") \n",
    "        print(f\"Hipotesis: {row['hypothesis']}\")\n",
    "        print(f\"True Label: {return_label(ground_truth)}\") \n",
    "        print(f\"Pred Label: {return_label(y_pred[idx])}\")\n",
    "        print(\"==========================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02c5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tf_gpu_research",
   "language": "python",
   "name": "tf_gpu_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
