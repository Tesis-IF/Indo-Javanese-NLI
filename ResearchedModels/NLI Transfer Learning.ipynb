{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d72962e",
   "metadata": {},
   "source": [
    "# Transfer Learning Approach for Cross-Lingual NLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a51bbdc",
   "metadata": {},
   "source": [
    "## Import Libraries and Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e523102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import gdown\n",
    "import time\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# set a seed value\n",
    "torch.manual_seed(205)\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import wandb\n",
    "\n",
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import BertTokenizer, BertForSequenceClassification #, XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7da96cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_TYPE = 'xlm-roberta-base'\n",
    "MODEL_TYPE = 'bert-base-multilingual-cased'\n",
    "MODEL_PATH = 'D:/Training/Machine Learning/NLP/NLI/saved_models/Indo-Javanese-NLI/ResearchedModels/'\n",
    "\n",
    "L_RATE = 3e-6\n",
    "MAX_LEN = 512\n",
    "NUM_EPOCHS = 6\n",
    "BATCH_SIZE = 2\n",
    "BATCH_NORM_EPSILON = 1e-5\n",
    "LAMBDA_L2 = 2e-5\n",
    "\n",
    "NUM_CORES = os.cpu_count() - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db31298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_API_KEY=97b170d223eb55f86fe1fbf9640831ad76381a74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjalaluddin-94\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %env WANDB_NOTEBOOK_NAME=/home/sagemaker-user/PPT/BERT_BiLSTM_Game_Review.ipynb\n",
    "%env WANDB_API_KEY=97b170d223eb55f86fe1fbf9640831ad76381a74\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af0da98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=javanese_nli\n",
      "env: WANDB_LOG_MODEL='end'\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=javanese_nli\n",
    "%env WANDB_LOG_MODEL='end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21714959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed2640d",
   "metadata": {},
   "source": [
    "## Download and Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52523ba",
   "metadata": {},
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bedd4315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uri = \"https://drive.google.com/uc?id=1aE9w2rqgW-j3PTgjnmHDjulNwp-Znb6i\"\n",
    "# output = \"dataset/indo_java_nli_training.csv\"\n",
    "# if not os.path.exists(\"dataset/\"):\n",
    "#   os.makedirs(\"dataset/\")\n",
    "# gdown.download(url=uri, output=output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aaa3ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uri = \"https://drive.google.com/uc?id=1YlQ9_8CvQbTSb5-2BjIfiYT-cy7pe6YM\"\n",
    "# output = \"dataset/indo_java_nli_validation.csv\"\n",
    "# if not os.path.exists(\"dataset/\"):\n",
    "#   os.makedirs(\"dataset/\")\n",
    "# gdown.download(url=uri, output=output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1952d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uri = \"https://drive.google.com/uc?id=1Zz_rHeI7fPUuA04zt9gCWyl5RYhrYPn0\"\n",
    "# output = \"dataset/indo_java_nli_testing.csv\"\n",
    "# if not os.path.exists(\"dataset/\"):\n",
    "#   os.makedirs(\"dataset/\")\n",
    "# gdown.download(url=uri, output=output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00585f5a",
   "metadata": {},
   "source": [
    "### Prepare Dataset for Student "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41501e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"D:/Training/Machine Learning/Datasets/NLI/IndoJavaNLI/indonli-with-java-chatgpt-training-data.csv\", sep='\\t')\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True) #shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c108af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dia membuat penampilan terakhirnya untuk klub ...</td>\n",
       "      <td>\"Isih lunga main kanggo klubé ing tanggal 20 N...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pengelola Nama Domain Internet Indonesia (Pand...</td>\n",
       "      <td>\"Pandi ora rencana mlebu domain.\"</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mayweather menepis anggapan bahwa McGregor yan...</td>\n",
       "      <td>Mayweather nganggukno McGregor minangka sumber...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tinggal bagaimana Real Madrid menjaga keutuhan...</td>\n",
       "      <td>Alvaro Morata duwe jatah tampilan sing banyuak...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sekte-sekte lain yang terpecah termasuk kelomp...</td>\n",
       "      <td>Grup Syiah lan sekte-sekte liyane sing penggal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  Dia membuat penampilan terakhirnya untuk klub ...   \n",
       "1  Pengelola Nama Domain Internet Indonesia (Pand...   \n",
       "2  Mayweather menepis anggapan bahwa McGregor yan...   \n",
       "3  Tinggal bagaimana Real Madrid menjaga keutuhan...   \n",
       "4  Sekte-sekte lain yang terpecah termasuk kelomp...   \n",
       "\n",
       "                                          hypothesis  label  \n",
       "0  \"Isih lunga main kanggo klubé ing tanggal 20 N...      1  \n",
       "1                  \"Pandi ora rencana mlebu domain.\"      2  \n",
       "2  Mayweather nganggukno McGregor minangka sumber...      2  \n",
       "3  Alvaro Morata duwe jatah tampilan sing banyuak...      2  \n",
       "4  Grup Syiah lan sekte-sekte liyane sing penggal...      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_student = pd.DataFrame()\n",
    "df_train_student[\"premise\"] = df_train[\"premise\"]\n",
    "df_train_student[\"hypothesis\"] = df_train[\"jv_hypothesis\"]\n",
    "df_train_student[\"label\"] = df_train[\"label\"]\n",
    "df_train_student.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4370c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv(\"D:/Training/Machine Learning/Datasets/NLI/IndoJavaNLI/indonli-with-java-chatgpt-validation-data.csv\", sep='\\t')\n",
    "df_valid = df_valid.sample(frac=1).reset_index(drop=True) #shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd1f962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lagu tersebut merupakan lagu latar untuk film ...</td>\n",
       "      <td>Lagu the Star diwenehi Carey.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hingga pertengahan tahun 1960-an, kimono masih...</td>\n",
       "      <td>Nanging ayeuna pakaian sehari-hari wadon Jepan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tim identifikasi Polres Kediri Kota masih mela...</td>\n",
       "      <td>Ratusan wong sing nggeleh menyang warung korba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dusun ini dikelilingi jalan semi aspal yang lu...</td>\n",
       "      <td>Dhukuh iki sisih ing wilayah angetan.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reger belajar musik di Muenchen dan Wiesbaden ...</td>\n",
       "      <td>Reger mbelajar musik nang Wiesbaden.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  Lagu tersebut merupakan lagu latar untuk film ...   \n",
       "1  Hingga pertengahan tahun 1960-an, kimono masih...   \n",
       "2  Tim identifikasi Polres Kediri Kota masih mela...   \n",
       "3  Dusun ini dikelilingi jalan semi aspal yang lu...   \n",
       "4  Reger belajar musik di Muenchen dan Wiesbaden ...   \n",
       "\n",
       "                                          hypothesis  label  \n",
       "0                      Lagu the Star diwenehi Carey.      1  \n",
       "1  Nanging ayeuna pakaian sehari-hari wadon Jepan...      1  \n",
       "2  Ratusan wong sing nggeleh menyang warung korba...      1  \n",
       "3              Dhukuh iki sisih ing wilayah angetan.      1  \n",
       "4               Reger mbelajar musik nang Wiesbaden.      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_student = pd.DataFrame()\n",
    "df_valid_student[\"premise\"] = df_valid[\"premise\"]\n",
    "df_valid_student[\"hypothesis\"] = df_valid[\"jv_hypothesis\"]\n",
    "df_valid_student[\"label\"] = df_valid[\"label\"]\n",
    "df_valid_student.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c34790a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"D:/Training/Machine Learning/Datasets/NLI/IndoJavaNLI/indonli-with-java-chatgpt-testing-data.csv\", sep='\\t')\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True) #shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf1c3fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya mengunjungi acara gelar di Northampton Un...</td>\n",
       "      <td>Ora tau ana acara gelar ing Universitas Northa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tayuban adalah desa di kecamatan Panjatan, Kul...</td>\n",
       "      <td>Tayuban iku sawijining desa.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berita tentang penipuan perusahaan yang telah ...</td>\n",
       "      <td>Warta babagan penipuan perusahaan, sing wis pi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kemunduran ini mengejutkan bagi tentara Austro...</td>\n",
       "      <td>Tentara Austro-Prusia yaiku tentara Denmark.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fokus terlalu lama pada gadget saat bekerja bi...</td>\n",
       "      <td>Gadget bisa ngobati stres.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  Saya mengunjungi acara gelar di Northampton Un...   \n",
       "1  Tayuban adalah desa di kecamatan Panjatan, Kul...   \n",
       "2  Berita tentang penipuan perusahaan yang telah ...   \n",
       "3  Kemunduran ini mengejutkan bagi tentara Austro...   \n",
       "4  Fokus terlalu lama pada gadget saat bekerja bi...   \n",
       "\n",
       "                                          hypothesis  label  \n",
       "0  Ora tau ana acara gelar ing Universitas Northa...      2  \n",
       "1                       Tayuban iku sawijining desa.      0  \n",
       "2  Warta babagan penipuan perusahaan, sing wis pi...      2  \n",
       "3       Tentara Austro-Prusia yaiku tentara Denmark.      1  \n",
       "4                         Gadget bisa ngobati stres.      1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_student = pd.DataFrame()\n",
    "df_test_student[\"premise\"] = df_test[\"premise\"]\n",
    "df_test_student[\"hypothesis\"] = df_test[\"jv_hypothesis\"]\n",
    "df_test_student[\"label\"] = df_test[\"label\"]\n",
    "df_test_student.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c463c38",
   "metadata": {},
   "source": [
    "### Prepare Dataset for Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15cd2f4",
   "metadata": {},
   "source": [
    "Dataset from teacher will be from \"IndoNLI\", and using Indonesian only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51c728fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset indonli (C:/Users/sufin/.cache/huggingface/datasets/indonli/indonli/1.1.0/d34041bd1d1a555a4bcb4ffdb9fe904778da6f7c5343209fc1485dd68121cb62)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sebelumnya, Barisan Relawan Jalan Perubahan (B...</td>\n",
       "      <td>Bara JP berencana melaporkan Fahri Hamzah ke M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sebuah penelitian yang dilakukan oleh Intensiv...</td>\n",
       "      <td>Semua pasien Corona dirawat tanpa alat bantu p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dalam pengaturan smartphone ada sebuah setting...</td>\n",
       "      <td>Ada setting dimana pengguna tidak dapat melaku...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grup musik ini beranggotakan 3 orang yaitu Cit...</td>\n",
       "      <td>Grup musik ini beranggotakan 3 orang.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Totok mengatakan, perseroannya berkomitmen unt...</td>\n",
       "      <td>Perseroan toktok berkomitmen untuk memuaskan p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10325</th>\n",
       "      <td>AeroConnect sendiri dapat diunduh melalui Appl...</td>\n",
       "      <td>Google PlayStore tidak menyediakan AeroConnect.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10326</th>\n",
       "      <td>Susy Susanti sukses mempersembahkan medali ema...</td>\n",
       "      <td>Susy Susanti tidak pernah mengikut Olimpiade.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10327</th>\n",
       "      <td>Jakarta (ANTARA News)-Setelah disibukkan denga...</td>\n",
       "      <td>Jennifer Lawrence samasekali tidak punya target.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10328</th>\n",
       "      <td>Sengketa proses bisa terjadi salah satunya seb...</td>\n",
       "      <td>Panwas kabupaten/kota juga disebut sebagai mah...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10329</th>\n",
       "      <td>Terlebih lagi dalam soal jarak, tempuh antar o...</td>\n",
       "      <td>Di Tempat wisata Wonosobo, hampir semua obyek ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10330 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 premise  \\\n",
       "0      Sebelumnya, Barisan Relawan Jalan Perubahan (B...   \n",
       "1      Sebuah penelitian yang dilakukan oleh Intensiv...   \n",
       "2      Dalam pengaturan smartphone ada sebuah setting...   \n",
       "3      Grup musik ini beranggotakan 3 orang yaitu Cit...   \n",
       "4      Totok mengatakan, perseroannya berkomitmen unt...   \n",
       "...                                                  ...   \n",
       "10325  AeroConnect sendiri dapat diunduh melalui Appl...   \n",
       "10326  Susy Susanti sukses mempersembahkan medali ema...   \n",
       "10327  Jakarta (ANTARA News)-Setelah disibukkan denga...   \n",
       "10328  Sengketa proses bisa terjadi salah satunya seb...   \n",
       "10329  Terlebih lagi dalam soal jarak, tempuh antar o...   \n",
       "\n",
       "                                              hypothesis label  \n",
       "0      Bara JP berencana melaporkan Fahri Hamzah ke M...     0  \n",
       "1      Semua pasien Corona dirawat tanpa alat bantu p...     2  \n",
       "2      Ada setting dimana pengguna tidak dapat melaku...     2  \n",
       "3                  Grup musik ini beranggotakan 3 orang.     0  \n",
       "4      Perseroan toktok berkomitmen untuk memuaskan p...     0  \n",
       "...                                                  ...   ...  \n",
       "10325    Google PlayStore tidak menyediakan AeroConnect.     2  \n",
       "10326      Susy Susanti tidak pernah mengikut Olimpiade.     2  \n",
       "10327   Jennifer Lawrence samasekali tidak punya target.     1  \n",
       "10328  Panwas kabupaten/kota juga disebut sebagai mah...     0  \n",
       "10329  Di Tempat wisata Wonosobo, hampir semua obyek ...     0  \n",
       "\n",
       "[10330 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_ds = load_dataset('indonli', split=\"train\")\n",
    "list_all_train = [df_train_ds['premise'], df_train_ds['hypothesis'], df_train_ds['label']]\n",
    "df_train_t = pd.DataFrame(list_all_train).transpose()\n",
    "df_train_t.columns = ['premise', 'hypothesis', 'label']\n",
    "df_train_t = df_train_t.sample(frac=1).reset_index(drop=True)\n",
    "display(df_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aebc677b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count per class train: 0    3476\n",
      "2    3439\n",
      "1    3415\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Count per class train:\", df_train_t['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66c4ed73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset indonli (C:/Users/sufin/.cache/huggingface/datasets/indonli/indonli/1.1.0/d34041bd1d1a555a4bcb4ffdb9fe904778da6f7c5343209fc1485dd68121cb62)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beberapa kali, anggota keluarganya yang dulu—K...</td>\n",
       "      <td>Anggota Keluarga Naito tidak mengenal Hyogo.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semula SMMA ditetapkan sebagai cagar alam oleh...</td>\n",
       "      <td>Luas cagar alam SMMA sekarang melebihi 20 ha.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alessandria adalah sebuah provinsi di regione ...</td>\n",
       "      <td>Alessandria terletak di Italia.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Ini karena adanya peningkatan pada tarif angk...</td>\n",
       "      <td>Peningkatan tarif kereta api memengaruhi harga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Selama di sekolah, dikisahkan Gomez kerap mena...</td>\n",
       "      <td>Gomez memperhatikan gurunya di sekolah pada ja...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>Apalagi sekarang, visa tidak diperlukan untuk ...</td>\n",
       "      <td>Banyak turis menyalahgunakan keabsenan visa se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>Dibangun dengan tinggi 36 meter dengan 4 tingk...</td>\n",
       "      <td>Bangunan monumen Jam Gadang ini dibangun denga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>\"Kalau bunga acuan turun, 3-4 bulan ke depan b...</td>\n",
       "      <td>Bank yang menyesuaikan hanya Bank Indonesia,.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>Alasan yang diungkapkan PSSI tak lebih karena ...</td>\n",
       "      <td>Dua pemain tetap bisa bergabung dalam persiapa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>Jeffry Daniel Waworuntu adalah seorang model, ...</td>\n",
       "      <td>Daniel merupakan seorang pembawa acara Indonesia.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2197 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "0     Beberapa kali, anggota keluarganya yang dulu—K...   \n",
       "1     Semula SMMA ditetapkan sebagai cagar alam oleh...   \n",
       "2     Alessandria adalah sebuah provinsi di regione ...   \n",
       "3     \"Ini karena adanya peningkatan pada tarif angk...   \n",
       "4     Selama di sekolah, dikisahkan Gomez kerap mena...   \n",
       "...                                                 ...   \n",
       "2192  Apalagi sekarang, visa tidak diperlukan untuk ...   \n",
       "2193  Dibangun dengan tinggi 36 meter dengan 4 tingk...   \n",
       "2194  \"Kalau bunga acuan turun, 3-4 bulan ke depan b...   \n",
       "2195  Alasan yang diungkapkan PSSI tak lebih karena ...   \n",
       "2196  Jeffry Daniel Waworuntu adalah seorang model, ...   \n",
       "\n",
       "                                             hypothesis label  \n",
       "0          Anggota Keluarga Naito tidak mengenal Hyogo.     2  \n",
       "1         Luas cagar alam SMMA sekarang melebihi 20 ha.     1  \n",
       "2                       Alessandria terletak di Italia.     0  \n",
       "3     Peningkatan tarif kereta api memengaruhi harga...     1  \n",
       "4     Gomez memperhatikan gurunya di sekolah pada ja...     1  \n",
       "...                                                 ...   ...  \n",
       "2192  Banyak turis menyalahgunakan keabsenan visa se...     1  \n",
       "2193  Bangunan monumen Jam Gadang ini dibangun denga...     0  \n",
       "2194      Bank yang menyesuaikan hanya Bank Indonesia,.     1  \n",
       "2195  Dua pemain tetap bisa bergabung dalam persiapa...     1  \n",
       "2196  Daniel merupakan seorang pembawa acara Indonesia.     0  \n",
       "\n",
       "[2197 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_valid_ds = load_dataset('indonli', split=\"validation\")\n",
    "list_all_valid = [df_valid_ds['premise'], df_valid_ds['hypothesis'], df_valid_ds['label']]\n",
    "df_valid_t = pd.DataFrame(list_all_valid).transpose()\n",
    "df_valid_t.columns = ['premise', 'hypothesis', 'label']\n",
    "df_valid_t = df_valid_t.sample(frac=1).reset_index(drop=True)\n",
    "display(df_valid_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edefebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count per class valid: 0    807\n",
      "2    749\n",
      "1    641\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Count per class valid:\", df_valid_t['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "827c72ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset indonli (C:/Users/sufin/.cache/huggingface/datasets/indonli/indonli/1.1.0/d34041bd1d1a555a4bcb4ffdb9fe904778da6f7c5343209fc1485dd68121cb62)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jordan Nagai adalah seorang aktor pengisi suar...</td>\n",
       "      <td>Jordan Nagai terkenal di kalangan anak-anak.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sejak pemerintahan jatuh ke tangan China pada ...</td>\n",
       "      <td>China sangat kejam terutama pada Hong Kong.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hak cipta karya yang dibuat oleh pekerja lepas...</td>\n",
       "      <td>Pekerja lepas AS tidak pernah khawatir karena ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sasando adalah sebuah alat musik dawai yang di...</td>\n",
       "      <td>Dalam bahasa Rote, kata Sandu artinya bergetar.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Presiden Soekarno mengeluarkan Keputusan Presi...</td>\n",
       "      <td>Hari Kartini diperingati setiap tanggal 21 April.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>Apalagi sekarang sudah ada inisiatif masyaraka...</td>\n",
       "      <td>Terdapat ban yang disewakan oleh masyarakat.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>Kabupaten ini dibentuk berdasarkan Undang-Unda...</td>\n",
       "      <td>Undang-Undang Nomor 27 Tahun 2008 tidak memkar...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>Fly Emirates adalah sponsor AC Milan mulai dar...</td>\n",
       "      <td>Bwin.com adalah sponsor Milan sebelum Fly Emir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>Sejarah sepak bola di Indonesia diawali dengan...</td>\n",
       "      <td>Sejarah sepak bola di Indonesia diawali oleh S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>Karst mengandung makna bentang alam yang terbe...</td>\n",
       "      <td>Batuan gamping hanya ada di lautan.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "0     Jordan Nagai adalah seorang aktor pengisi suar...   \n",
       "1     Sejak pemerintahan jatuh ke tangan China pada ...   \n",
       "2     Hak cipta karya yang dibuat oleh pekerja lepas...   \n",
       "3     Sasando adalah sebuah alat musik dawai yang di...   \n",
       "4     Presiden Soekarno mengeluarkan Keputusan Presi...   \n",
       "...                                                 ...   \n",
       "2196  Apalagi sekarang sudah ada inisiatif masyaraka...   \n",
       "2197  Kabupaten ini dibentuk berdasarkan Undang-Unda...   \n",
       "2198  Fly Emirates adalah sponsor AC Milan mulai dar...   \n",
       "2199  Sejarah sepak bola di Indonesia diawali dengan...   \n",
       "2200  Karst mengandung makna bentang alam yang terbe...   \n",
       "\n",
       "                                             hypothesis label  \n",
       "0          Jordan Nagai terkenal di kalangan anak-anak.     1  \n",
       "1           China sangat kejam terutama pada Hong Kong.     1  \n",
       "2     Pekerja lepas AS tidak pernah khawatir karena ...     0  \n",
       "3       Dalam bahasa Rote, kata Sandu artinya bergetar.     0  \n",
       "4     Hari Kartini diperingati setiap tanggal 21 April.     0  \n",
       "...                                                 ...   ...  \n",
       "2196       Terdapat ban yang disewakan oleh masyarakat.     0  \n",
       "2197  Undang-Undang Nomor 27 Tahun 2008 tidak memkar...     2  \n",
       "2198  Bwin.com adalah sponsor Milan sebelum Fly Emir...     0  \n",
       "2199  Sejarah sepak bola di Indonesia diawali oleh S...     1  \n",
       "2200                Batuan gamping hanya ada di lautan.     1  \n",
       "\n",
       "[2201 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_ds = load_dataset('indonli', split=\"test_lay\")\n",
    "list_all_test = [df_test_ds['premise'], df_test_ds['hypothesis'], df_test_ds['label']]\n",
    "df_test_t = pd.DataFrame(list_all_test).transpose()\n",
    "df_test_t.columns = ['premise', 'hypothesis', 'label']\n",
    "df_test_t = df_test_t.sample(frac=1).reset_index(drop=True)\n",
    "display(df_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa24c6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count per class test: 0    808\n",
      "2    764\n",
      "1    629\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Count per class test:\", df_test_t['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da092653",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66688a9d",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a1737ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_TYPE)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88b3565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df_data = df\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sentence1 = self.df_data.loc[index, 'premise']\n",
    "        sentence2 = self.df_data.loc[index, 'hypothesis']\n",
    "        \n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sentence1,\n",
    "            sentence2,\n",
    "            add_special_tokens = True,\n",
    "            max_length = MAX_LEN,\n",
    "            truncation='longest_first',\n",
    "            padding = 'max_length',\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt'\n",
    "        )\n",
    "        \n",
    "        padded_token_list = encoded_dict['input_ids'][0]\n",
    "        att_mask = encoded_dict['attention_mask'][0]\n",
    "        \n",
    "        target = torch.tensor(self.df_data.loc[index, 'label'])\n",
    "        sample = {\"input_ids\": padded_token_list, \"attention_mask\": att_mask, \"label\": target}\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e52c69",
   "metadata": {},
   "source": [
    "Tokenize student dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7840b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_student_cmp = CompDataset(df_train_student)\n",
    "# valid_data_student_cmp = CompDataset(df_valid_student)\n",
    "# test_data_student_cmp = CompDataset(df_test_student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aecbe0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_student_loader = DataLoader(\n",
    "#     train_data_student_cmp,\n",
    "#     batch_size = BATCH_SIZE\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a021cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_student_loader = DataLoader(\n",
    "#     valid_data_student_cmp,\n",
    "#     batch_size = BATCH_SIZE\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcc2da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_student_loader = DataLoader(\n",
    "#     test_data_student_cmp,\n",
    "#     batch_size = BATCH_SIZE\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bd6d49",
   "metadata": {},
   "source": [
    "Tokenize teacher dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f22bfca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_teacher_cmp = CompDataset(df_train_t)\n",
    "valid_data_teacher_cmp = CompDataset(df_valid_t)\n",
    "test_data_teacher_cmp = CompDataset(df_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e82781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_teacher_loader = DataLoader(\n",
    "    train_data_teacher_cmp,\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e403658",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_teacher_loader = DataLoader(\n",
    "    valid_data_teacher_cmp,\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d45be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_teacher_loader = DataLoader(\n",
    "    test_data_teacher_cmp,\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c5e5b",
   "metadata": {},
   "source": [
    "## Hidden State Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c3165f",
   "metadata": {},
   "source": [
    "Define model for teacher and student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7adf2736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_teacher = BertForSequenceClassification.from_pretrained(\n",
    "    MODEL_TYPE, \n",
    "    num_labels = 3,\n",
    "    output_hidden_states=True\n",
    ")\n",
    "# model_teacher = model_teacher.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f94d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_student = BertForSequenceClassification.from_pretrained(\n",
    "#     MODEL_TYPE, \n",
    "#     num_labels = 3,\n",
    "#     output_hidden_states=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fb21438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_final_hidden_state(the_model, the_dataloader):\n",
    "    the_model.eval()\n",
    "    \n",
    "    context_vector = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        t = tqdm(enumerate(the_dataloader), total=len(the_dataloader), colour=\"green\", leave=True, position=0)\n",
    "        for batch, datas in t:\n",
    "#             inpt_ids = datas[\"input_ids\"].to(device)\n",
    "#             att_mask = datas[\"attention_mask\"].to(device)\n",
    "#             label = datas[\"label\"].to(device)\n",
    "            inpt_ids = datas[\"input_ids\"]\n",
    "            att_mask = datas[\"attention_mask\"]\n",
    "            label = datas[\"label\"]\n",
    "\n",
    "            outputs = the_model(\n",
    "                input_ids = inpt_ids,\n",
    "                attention_mask = att_mask,\n",
    "                labels = label\n",
    "            )\n",
    "\n",
    "            # Take last hidden state\n",
    "    #         hidden_states = outputs.hidden_states[0] # torch.Size([1, 512, 768]) # this is the first layer\n",
    "            last_hidden_state = outputs.hidden_states[-1:][0] # torch.Size([1, 512, 768]) # take the last hidden layer\n",
    "\n",
    "            # Take CLS only\n",
    "            cont_vec = last_hidden_state[0][0] # torch.Size([768])\n",
    "            cont_vec = cont_vec[None, :] # torch.Size([1, 768])\n",
    "            context_vector.append(cont_vec) \n",
    "            labels.append(label)\n",
    "\n",
    "            t.set_description(f\"Extracting CLS token vector [{batch+1}/{len(the_dataloader)}]...\")\n",
    "    \n",
    "    return context_vector, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5757b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_vec_student, labels_student = extract_final_hidden_state(model_student, train_student_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97f4323e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1136"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4565ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting CLS token vector [1381/5165]...:  27%|\u001b[32m████████▌                       \u001b[0m| 1381/5165 [51:40<2:21:18,  2.24s/it]\u001b[0mBe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Extracting CLS token vector [1504/5165]...:  29%|\u001b[32m█████████▎                      \u001b[0m| 1504/5165 [56:16<2:15:42,  2.22s/it]\u001b[0mBe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Extracting CLS token vector [2344/5165]...:  45%|\u001b[32m█████████████▌                \u001b[0m| 2344/5165 [1:28:15<1:49:07,  2.32s/it]\u001b[0mBe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Extracting CLS token vector [2632/5165]...:  51%|\u001b[32m███████████████▎              \u001b[0m| 2632/5165 [1:39:20<1:34:30,  2.24s/it]\u001b[0mBe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Extracting CLS token vector [5000/5165]...:  97%|\u001b[32m██████████████████████████████▉ \u001b[0m| 5000/5165 [3:11:31<06:23,  2.33s/it]\u001b[0mBe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Extracting CLS token vector [5163/5165]...: 100%|\u001b[32m███████████████████████████████▉\u001b[0m| 5163/5165 [3:18:08<00:04,  2.45s/it]\u001b[0mBe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Extracting CLS token vector [5165/5165]...: 100%|\u001b[32m████████████████████████████████\u001b[0m| 5165/5165 [3:18:13<00:00,  2.30s/it]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "context_vec_train_teacher, labels_train_teacher = extract_final_hidden_state(model_teacher, train_teacher_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f7132b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting CLS token vector [1099/1099]...: 100%|\u001b[32m██████████████████████████████████\u001b[0m| 1099/1099 [42:59<00:00,  2.35s/it]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "context_vec_valid_teacher, labels_valid_teacher = extract_final_hidden_state(model_teacher, validation_teacher_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "859aeb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting CLS token vector [1101/1101]...: 100%|\u001b[32m██████████████████████████████████\u001b[0m| 1101/1101 [43:31<00:00,  2.37s/it]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "context_vec_test_teacher, labels_test_teacher = extract_final_hidden_state(model_teacher, test_teacher_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47d6a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, array_embed, array_lbl):\n",
    "        self.embedding = array_embed\n",
    "        self.label = array_lbl\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    def __getitem__(self, idx):\n",
    "        self.exact_data = self.embedding[idx]\n",
    "        self.exact_label = self.label[idx]\n",
    "        \n",
    "        returned_dict = {\n",
    "            \"x\": self.exact_data,\n",
    "            \"labels\": self.exact_label\n",
    "        }\n",
    "        \n",
    "        return returned_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f35feb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_teacher = EmbeddingDataset(context_vec_train_teacher, labels_train_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25eb4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_valid_teacher = EmbeddingDataset(context_vec_valid_teacher, labels_valid_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "283a7c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_teacher = EmbeddingDataset(context_vec_test_teacher, labels_test_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "976fe1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_student = EmbeddingDataset(context_vec_student, labels_student)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd468cb",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f386b07",
   "metadata": {},
   "source": [
    "Classifier for Teacher (scenario zero-shot from teacher directly to classify student data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3a849aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierTeacher(nn.Module):\n",
    "    def __init__(self, n_features, epsilon, n_labels):\n",
    "        super(ClassifierTeacher, self).__init__()\n",
    "        self.norm = nn.BatchNorm1d(\n",
    "            num_features = n_features,\n",
    "            eps = epsilon\n",
    "        )\n",
    "        self.fc = nn.Linear(\n",
    "            in_features = n_features,\n",
    "            out_features = n_labels\n",
    "        )\n",
    "        self.softm = nn.Softmax(\n",
    "            dim=1\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x[0,:,:]\n",
    "        y = self.norm(x)\n",
    "        y = self.fc(y)\n",
    "        y = self.softm(y)\n",
    "        \n",
    "        return {\"logits\": y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e39d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_teacher = ClassifierTeacher(\n",
    "    n_features = 768, # CLS token n_features\n",
    "    epsilon = BATCH_NORM_EPSILON,\n",
    "    n_labels = 3 # 3 labels: entails, neutral, and contradict\n",
    ")\n",
    "classifier_teacher = classifier_teacher.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e175723",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4490e8",
   "metadata": {},
   "source": [
    "Collect garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ce623e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2601"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ebef17",
   "metadata": {},
   "source": [
    "Function to compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5ecafed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average='micro')\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average='micro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average='weighted')\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1_score\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05adf552",
   "metadata": {},
   "source": [
    "Training using Trainer from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "108d6dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._resume_backend at 0x00000234748B5F70> (for pre_run_cell):\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\backcall\\backcall.py:104\u001b[0m, in \u001b[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m                 kwargs\u001b[38;5;241m.\u001b[39mpop(name)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:423\u001b[0m, in \u001b[0;36m_WandbInit._resume_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    422\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py:673\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    672\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[1;32m--> 673\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py:344\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[1;34m(self, resume)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[1;32m--> 344\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[1;34m(self, record, local)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[0;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x0000023420F4AA60> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\backcall\\backcall.py:104\u001b[0m, in \u001b[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m                 kwargs\u001b[38;5;241m.\u001b[39mpop(name)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:418\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py:665\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    664\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[1;32m--> 665\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py:340\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[1;34m(self, pause)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    339\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[1;34m(self, record, local)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[0;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    }
   ],
   "source": [
    "training_args_scenario_1 = TrainingArguments(\n",
    "    output_dir=MODEL_PATH + \"teacher-zero-shot/\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    weight_decay=LAMBDA_L2,\n",
    "    save_strategy=\"no\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    seed=101,\n",
    "    learning_rate=L_RATE,\n",
    "    report_to=\"wandb\", # \"none\"\n",
    "    run_name=\"scenario1-teacher-zero-shot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "70874945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._resume_backend at 0x00000234748B5F70> (for pre_run_cell):\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\backcall\\backcall.py:104\u001b[0m, in \u001b[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m                 kwargs\u001b[38;5;241m.\u001b[39mpop(name)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:423\u001b[0m, in \u001b[0;36m_WandbInit._resume_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    422\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py:673\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    672\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[1;32m--> 673\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py:344\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[1;34m(self, resume)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[1;32m--> 344\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[1;34m(self, record, local)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[0;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x0000023420F4AA60> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\backcall\\backcall.py:104\u001b[0m, in \u001b[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m                 kwargs\u001b[38;5;241m.\u001b[39mpop(name)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:418\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py:665\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    664\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[1;32m--> 665\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py:340\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[1;34m(self, pause)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    339\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[1;34m(self, record, local)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[0;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    }
   ],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        data = inputs.get(\"x\")\n",
    "        # forward pass\n",
    "        print(\"data\", data)\n",
    "        outputs = model(data)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_func_teacher = nn.CrossEntropyLoss()\n",
    "        loss = loss_func_teacher(logits, labels)\n",
    "        # compute custom loss (suppose one has 3 labels with different weights)\n",
    "#         loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0, 3.0]))\n",
    "#         loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f7d22c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_scenario_1 = CustomTrainer(\n",
    "    model=classifier_teacher,\n",
    "    args=training_args_scenario_1,\n",
    "    train_dataset=dataset_train_teacher,\n",
    "    eval_dataset=dataset_valid_teacher,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c7a41189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs {'x': tensor([[[-0.0740,  0.0902,  0.0220,  ...,  0.0896, -0.0318,  0.0350]],\n",
      "\n",
      "        [[-0.0879, -0.1221, -0.1729,  ...,  0.1188,  0.1163, -0.1308]]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 768])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer_scenario_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\transformers\\trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1630\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1631\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1632\u001b[0m )\n\u001b[1;32m-> 1633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1638\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\transformers\\trainer.py:1902\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1900\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1902\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1905\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1906\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1907\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1908\u001b[0m ):\n\u001b[0;32m   1909\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1910\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\transformers\\trainer.py:2645\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2644\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2645\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2648\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[75], line 6\u001b[0m, in \u001b[0;36mCustomTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, inputs)\n\u001b[1;32m----> 6\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m loss_func_teacher \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[70], line 17\u001b[0m, in \u001b[0;36mClassifierTeacher.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m0\u001b[39m,:,:]\n\u001b[1;32m---> 17\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(y)\n\u001b[0;32m     19\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftm(y)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\torch\\nn\\functional.py:2436\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2424\u001b[0m         batch_norm,\n\u001b[0;32m   2425\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2433\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m   2434\u001b[0m     )\n\u001b[0;32m   2435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m-> 2436\u001b[0m     \u001b[43m_verify_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[0;32m   2439\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[0;32m   2440\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my-torch\\lib\\site-packages\\torch\\nn\\functional.py:2404\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m   2402\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   2403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 2404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(size))\n",
      "\u001b[1;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 768])"
     ]
    }
   ],
   "source": [
    "trainer_scenario_1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29242a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_scenario_1.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28db4729",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06706d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_scenario_1.save_model(MODEL_PATH + \"teacher-zero-shot/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae224d28",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d773b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_scenario_1 = trainer_scenario_1.predict(dataset_test_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing metrics:\", prediction_scenario_1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c8cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-torch",
   "language": "python",
   "name": "my-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
