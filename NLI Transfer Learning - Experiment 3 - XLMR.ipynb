{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-17T19:03:17.151113Z",
     "iopub.status.busy": "2023-07-17T19:03:17.150727Z",
     "iopub.status.idle": "2023-07-17T19:05:09.497402Z",
     "shell.execute_reply": "2023-07-17T19:05:09.496101Z",
     "shell.execute_reply.started": "2023-07-17T19:03:17.151083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.5)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.27.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (59.8.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.65.0)\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.6.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-fjri10qj\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-fjri10qj\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 9dc965bb404c2bb8e3c02eaa5eea6502af1aee1a\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.32.0.dev0) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.32.0.dev0) (4.6.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.32.0.dev0) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (2023.5.7)\n",
      "Collecting git+https://github.com/huggingface/accelerate.git\n",
      "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-oz0zl5aj\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-oz0zl5aj\n",
      "  Resolved https://github.com/huggingface/accelerate.git to commit 653ba110d31c86d3527bb88bf6209441c176ce11\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0.dev0) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0.dev0) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0.dev0) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0.dev0) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0.dev0) (2.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.22.0.dev0) (3.0.9)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (4.6.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.22.0.dev0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.22.0.dev0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U scikit-learn\n",
    "! pip install wandb\n",
    "! pip install tqdm\n",
    "! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
    "! pip install -U git+https://github.com/huggingface/transformers.git\n",
    "! pip install -U git+https://github.com/huggingface/accelerate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.501622Z",
     "iopub.status.busy": "2023-07-17T19:05:09.500433Z",
     "iopub.status.idle": "2023-07-17T19:05:09.512657Z",
     "shell.execute_reply": "2023-07-17T19:05:09.511116Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.501579Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import gdown\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# set a seed value\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import wandb\n",
    "\n",
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AdamW, EarlyStoppingCallback\n",
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "from transformers import XLMRobertaModel, XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.514696Z",
     "iopub.status.busy": "2023-07-17T19:05:09.514198Z",
     "iopub.status.idle": "2023-07-17T19:05:09.528822Z",
     "shell.execute_reply": "2023-07-17T19:05:09.527646Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.514654Z"
    }
   },
   "outputs": [],
   "source": [
    "TOKENIZER_TYPE = 'xlm-roberta-base'\n",
    "MBERT_TYPE = 'xlm-roberta-base'\n",
    "MODEL_TEACHER_TYPE = 'jalaluddin94/xlmr-nli-indoindo'\n",
    "HF_MODEL_NAME = 'jalaluddin94/trf-learning-indojavanesenli-xlmr'\n",
    "\n",
    "# DATASET_NAME = 'jalaluddin94/IndoJavaneseNLI'\n",
    "\n",
    "STUDENT_LRATE = 2e-5\n",
    "LAMBDA_KLD = 0.5 # between 0.01 - 0.5\n",
    "MAX_LEN = 512\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 8\n",
    "BATCH_NORM_EPSILON = 1e-5\n",
    "LAMBDA_L2 = 3e-5\n",
    "\n",
    "HF_TOKEN = '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'\n",
    "\n",
    "NUM_CORES = os.cpu_count() - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n",
      "Downloading training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1j5iclahnkuk_jCZS12ZB9a4QN_XAJ9pt\n",
      "To: D:\\Training\\Machine Learning\\NLP\\NLI\\datasets\\train.csv\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 6.43M/6.43M [00:02<00:00, 2.17MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1A4M8uS3bl__-Jugq11cOCAXdvXdMKBju\n",
      "To: D:\\Training\\Machine Learning\\NLP\\NLI\\datasets\\validation.csv\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1.32M/1.32M [00:02<00:00, 660kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading testing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1h011UmkFi9gM1yGEicizrGAUxgmPI1TP\n",
      "To: D:\\Training\\Machine Learning\\NLP\\NLI\\datasets\\test.csv\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 893k/893k [00:00<00:00, 4.31MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'datasets/test.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing dataset\n",
    "print(\"Preparing dataset...\")\n",
    "if not os.path.exists(\"datasets/\"):\n",
    "  os.makedirs(\"datasets/\")\n",
    "\n",
    "# Download dataset\n",
    "print(\"Downloading training data...\")\n",
    "uri = \"https://drive.google.com/uc?id=1j5iclahnkuk_jCZS12ZB9a4QN_XAJ9pt\"\n",
    "output = \"datasets/train.csv\"\n",
    "gdown.download(url=uri, output=output, quiet=False, fuzzy=True)\n",
    "\n",
    "print(\"Downloading validation data...\")\n",
    "uri = \"https://drive.google.com/uc?id=1A4M8uS3bl__-Jugq11cOCAXdvXdMKBju\"\n",
    "output = \"datasets/validation.csv\"\n",
    "gdown.download(url=uri, output=output, quiet=False, fuzzy=True)\n",
    "\n",
    "print(\"Downloading testing data...\")\n",
    "uri = \"https://drive.google.com/uc?id=1h011UmkFi9gM1yGEicizrGAUxgmPI1TP\"\n",
    "output = \"datasets/test.csv\"\n",
    "gdown.download(url=uri, output=output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid.\n",
      "Your token has been saved to C:\\Users\\sufin\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.532691Z",
     "iopub.status.busy": "2023-07-17T19:05:09.532271Z",
     "iopub.status.idle": "2023-07-17T19:05:09.549191Z",
     "shell.execute_reply": "2023-07-17T19:05:09.548094Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.532652Z"
    }
   },
   "outputs": [],
   "source": [
    "%env WANDB_API_KEY=97b170d223eb55f86fe1fbf9640831ad76381a74\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.551695Z",
     "iopub.status.busy": "2023-07-17T19:05:09.551198Z",
     "iopub.status.idle": "2023-07-17T19:05:09.562505Z",
     "shell.execute_reply": "2023-07-17T19:05:09.561414Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.551657Z"
    }
   },
   "outputs": [],
   "source": [
    "%env WANDB_LOG_MODEL='end'\n",
    "run = wandb.init(\n",
    "  project=\"javanese_nli\",\n",
    "  notes=\"Experiment transfer learning on Bandyopadhyay's paper using XLMR\",\n",
    "  name=\"trf-lrn-experiment-xlmr-epoch5-batchsize8-lamdakld0.5\",\n",
    "  tags=[\"transferlearning\", \"bandyopadhyay\", \"xlmr\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.565157Z",
     "iopub.status.busy": "2023-07-17T19:05:09.564339Z",
     "iopub.status.idle": "2023-07-17T19:05:09.576350Z",
     "shell.execute_reply": "2023-07-17T19:05:09.574636Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.565117Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_AGENT_MAX_INITIAL_FAILURES\"]=\"1024\"\n",
    "os.environ[\"WANDB_AGENT_DISABLE_FLAPPING\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.578791Z",
     "iopub.status.busy": "2023-07-17T19:05:09.578485Z",
     "iopub.status.idle": "2023-07-17T19:05:09.589132Z",
     "shell.execute_reply": "2023-07-17T19:05:09.588093Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.578748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Dataset for Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.591459Z",
     "iopub.status.busy": "2023-07-17T19:05:09.590783Z",
     "iopub.status.idle": "2023-07-17T19:05:09.747569Z",
     "shell.execute_reply": "2023-07-17T19:05:09.746392Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.591422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amerika Serikat pada 15 April 1927 pernah dila...</td>\n",
       "      <td>ora tau ana banjir neng mississippi.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pesawat pengintai Amerika Serikat menemukan ar...</td>\n",
       "      <td>markas komando satuma ora ngentuk info apa-apa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bahasa Arab merupakan bahasa Semitik dan tata ...</td>\n",
       "      <td>basa arab ora nduweni tata basa.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robert Alberts pun diusir keluar oleh wasit as...</td>\n",
       "      <td>wektu tambahan sing diwenehna yaiku lima menit.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karst mengandung makna bentang alam yang terbe...</td>\n",
       "      <td>karst bentuk saka batu gamping neng segaran si...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  Amerika Serikat pada 15 April 1927 pernah dila...   \n",
       "1  Pesawat pengintai Amerika Serikat menemukan ar...   \n",
       "2  Bahasa Arab merupakan bahasa Semitik dan tata ...   \n",
       "3  Robert Alberts pun diusir keluar oleh wasit as...   \n",
       "4  Karst mengandung makna bentang alam yang terbe...   \n",
       "\n",
       "                                          hypothesis  label  \n",
       "0               ora tau ana banjir neng mississippi.      2  \n",
       "1  markas komando satuma ora ngentuk info apa-apa...      2  \n",
       "2                   basa arab ora nduweni tata basa.      2  \n",
       "3    wektu tambahan sing diwenehna yaiku lima menit.      2  \n",
       "4  karst bentuk saka batu gamping neng segaran si...      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"datasets/train.csv\", sep='\\t')\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True) #shuffle the data\n",
    "\n",
    "df_train_student = pd.DataFrame()\n",
    "df_train_student[\"premise\"] = df_train[\"premise\"]\n",
    "df_train_student[\"hypothesis\"] = df_train[\"jv_hypothesis_mongo\"]\n",
    "df_train_student[\"label\"] = df_train[\"label\"]\n",
    "df_train_student.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.749869Z",
     "iopub.status.busy": "2023-07-17T19:05:09.749496Z",
     "iopub.status.idle": "2023-07-17T19:05:09.798482Z",
     "shell.execute_reply": "2023-07-17T19:05:09.796267Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.749834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Sempat ditelepon katanya di Medan terus tiba ...</td>\n",
       "      <td>wong iku ora tau ngomong dheweke ana ing medan.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pada balapan ini, Hamilton mengungguli Daniel ...</td>\n",
       "      <td>valtteri bottas nglinuwihi hamilton.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Selagi masih punya kekuatan, mereka pun melawa...</td>\n",
       "      <td>superman isih nduwe kekuwatan.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kini, Bukittinggi punya peran baru, yakni menj...</td>\n",
       "      <td>akeh objek pariwisata anyar neng bukittingi.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karena itu, dokter lebih suka menggunakan isti...</td>\n",
       "      <td>dokter luwih seneng nggunakne bebasan \"tumor o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  \"Sempat ditelepon katanya di Medan terus tiba ...   \n",
       "1  Pada balapan ini, Hamilton mengungguli Daniel ...   \n",
       "2  Selagi masih punya kekuatan, mereka pun melawa...   \n",
       "3  Kini, Bukittinggi punya peran baru, yakni menj...   \n",
       "4  Karena itu, dokter lebih suka menggunakan isti...   \n",
       "\n",
       "                                          hypothesis  label  \n",
       "0    wong iku ora tau ngomong dheweke ana ing medan.      2  \n",
       "1               valtteri bottas nglinuwihi hamilton.      2  \n",
       "2                     superman isih nduwe kekuwatan.      1  \n",
       "3       akeh objek pariwisata anyar neng bukittingi.      1  \n",
       "4  dokter luwih seneng nggunakne bebasan \"tumor o...      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.read_csv(\"datasets/validation.csv\", sep='\\t')\n",
    "df_valid = df_valid.sample(frac=1).reset_index(drop=True) #shuffle the data\n",
    "\n",
    "df_valid_student = pd.DataFrame()\n",
    "df_valid_student[\"premise\"] = df_valid[\"premise\"]\n",
    "df_valid_student[\"hypothesis\"] = df_valid[\"jv_hypothesis_mongo\"]\n",
    "df_valid_student[\"label\"] = df_valid[\"label\"]\n",
    "df_valid_student.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.804040Z",
     "iopub.status.busy": "2023-07-17T19:05:09.802986Z",
     "iopub.status.idle": "2023-07-17T19:05:09.856609Z",
     "shell.execute_reply": "2023-07-17T19:05:09.855433Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.803997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perang Revolusi Amerika berakhir pada 15 April...</td>\n",
       "      <td>perang revolusi amerika yaiku perang kemerdeka...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dinas Daerah dipimpin oleh seorang Kepala Dina...</td>\n",
       "      <td>sirah dinas ana didhuwur bupati sirah daerah.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Memasuki kualifikasi 2 (Q2), persaingan di ant...</td>\n",
       "      <td>mung sebastian vettel sing gumanti ban teles m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Presipitasi merupakan proses terjadinya hujan ...</td>\n",
       "      <td>kedadeane udan awak saka telu proses.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summer of Love kini tengah diedit di beberapa ...</td>\n",
       "      <td>Reitmen asale saka Australi.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  Perang Revolusi Amerika berakhir pada 15 April...   \n",
       "1  Dinas Daerah dipimpin oleh seorang Kepala Dina...   \n",
       "2  Memasuki kualifikasi 2 (Q2), persaingan di ant...   \n",
       "3  Presipitasi merupakan proses terjadinya hujan ...   \n",
       "4  Summer of Love kini tengah diedit di beberapa ...   \n",
       "\n",
       "                                          hypothesis  label  \n",
       "0  perang revolusi amerika yaiku perang kemerdeka...      0  \n",
       "1      sirah dinas ana didhuwur bupati sirah daerah.      2  \n",
       "2  mung sebastian vettel sing gumanti ban teles m...      2  \n",
       "3              kedadeane udan awak saka telu proses.      1  \n",
       "4                       Reitmen asale saka Australi.      2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"datasets/test.csv\", sep='\\t')\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True) #shuffle the data\n",
    "\n",
    "df_test_student = pd.DataFrame()\n",
    "df_test_student[\"premise\"] = df_test[\"premise\"]\n",
    "df_test_student[\"premise\"] = df_test_student[\"premise\"].astype(str)\n",
    "df_test_student[\"hypothesis\"] = df_test[\"jv_hypothesis\"]\n",
    "df_test_student[\"hypothesis\"] = df_test_student[\"hypothesis\"].astype(str)\n",
    "df_test_student[\"label\"] = df_test[\"label\"]\n",
    "df_test_student.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Dataset for Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset from teacher will be from \"IndoNLI\", and using Indonesian only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.860244Z",
     "iopub.status.busy": "2023-07-17T19:05:09.859268Z",
     "iopub.status.idle": "2023-07-17T19:05:09.884890Z",
     "shell.execute_reply": "2023-07-17T19:05:09.882628Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.860205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pada 2012, mereka menghasilkan enam pemuda yan...</td>\n",
       "      <td>Telah terjadi proses pemungutan suara.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adveksi adalah proses perpindahan awan dari sa...</td>\n",
       "      <td>Awan dapat berpindah dari satu titik ke titik ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Republik Federal Sosialis Yugoslavia pecah pad...</td>\n",
       "      <td>Pemecahan Republik Federal Sosialis Yugoslavia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Walaupun Perejil tidak tercantum dalam perjanj...</td>\n",
       "      <td>Beberapa wilayah Maroko disebutkan pada Perjan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mereka mendorong orang untuk mendobrak stigma ...</td>\n",
       "      <td>Ada stigma seputar persoalan kesehatan jiwa ya...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10325</th>\n",
       "      <td>Lagu itu kental dengan nuansa musik 1960-an da...</td>\n",
       "      <td>Lagu itu tidak memiliki alunan musik keyboard.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10326</th>\n",
       "      <td>Dalam satu CD, terdapat 12 lagu penutup yang d...</td>\n",
       "      <td>Kurosaki merilis 12 lagu pada tanggal 22 Septe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10327</th>\n",
       "      <td>Monaco sendiri adalah tim yang paling banyak m...</td>\n",
       "      <td>Monaco memiliki banyak tim.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10328</th>\n",
       "      <td>China juga kembali meraih gelar di kategori ga...</td>\n",
       "      <td>Li Junhui merupakan pasangan Liu Yuchen.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10329</th>\n",
       "      <td>Penggunaan zat kimia berbahaya untuk sterilisa...</td>\n",
       "      <td>Penggunaan zat kimia tidak perlu diperhatikan.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10330 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 premise  \\\n",
       "0      Pada 2012, mereka menghasilkan enam pemuda yan...   \n",
       "1      Adveksi adalah proses perpindahan awan dari sa...   \n",
       "2      Republik Federal Sosialis Yugoslavia pecah pad...   \n",
       "3      Walaupun Perejil tidak tercantum dalam perjanj...   \n",
       "4      Mereka mendorong orang untuk mendobrak stigma ...   \n",
       "...                                                  ...   \n",
       "10325  Lagu itu kental dengan nuansa musik 1960-an da...   \n",
       "10326  Dalam satu CD, terdapat 12 lagu penutup yang d...   \n",
       "10327  Monaco sendiri adalah tim yang paling banyak m...   \n",
       "10328  China juga kembali meraih gelar di kategori ga...   \n",
       "10329  Penggunaan zat kimia berbahaya untuk sterilisa...   \n",
       "\n",
       "                                              hypothesis  label  \n",
       "0                 Telah terjadi proses pemungutan suara.      1  \n",
       "1      Awan dapat berpindah dari satu titik ke titik ...      0  \n",
       "2      Pemecahan Republik Federal Sosialis Yugoslavia...      1  \n",
       "3      Beberapa wilayah Maroko disebutkan pada Perjan...      0  \n",
       "4      Ada stigma seputar persoalan kesehatan jiwa ya...      0  \n",
       "...                                                  ...    ...  \n",
       "10325     Lagu itu tidak memiliki alunan musik keyboard.      2  \n",
       "10326  Kurosaki merilis 12 lagu pada tanggal 22 Septe...      0  \n",
       "10327                        Monaco memiliki banyak tim.      1  \n",
       "10328           Li Junhui merupakan pasangan Liu Yuchen.      0  \n",
       "10329     Penggunaan zat kimia tidak perlu diperhatikan.      2  \n",
       "\n",
       "[10330 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_t = pd.DataFrame()\n",
    "df_train_t[\"premise\"] = df_train[\"premise\"]\n",
    "df_train_t[\"hypothesis\"] = df_train[\"hypothesis\"]\n",
    "df_train_t[\"label\"] = df_train[\"label\"]\n",
    "df_train_t = df_train_t.sample(frac=1).reset_index(drop=True)\n",
    "display(df_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.887147Z",
     "iopub.status.busy": "2023-07-17T19:05:09.886735Z",
     "iopub.status.idle": "2023-07-17T19:05:09.896426Z",
     "shell.execute_reply": "2023-07-17T19:05:09.895073Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.887110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count per class train:\n",
      "0    3476\n",
      "2    3439\n",
      "1    3415\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Count per class train:\") \n",
    "print(df_train_t['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.899523Z",
     "iopub.status.busy": "2023-07-17T19:05:09.898036Z",
     "iopub.status.idle": "2023-07-17T19:05:09.922615Z",
     "shell.execute_reply": "2023-07-17T19:05:09.920650Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.899491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beberapa analis telah menyarankan bahwa Huawai...</td>\n",
       "      <td>Beberapa analis mendukung Huawei.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Seperti film laga, kolosal,\" ujar aktris 33 t...</td>\n",
       "      <td>Aktris itu biasa bermain pada film laga.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Untuk video, Air 2 bisa merekam video 4K 60fps...</td>\n",
       "      <td>Air 2 dapat merekam video dengan baik.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saya menulis hal ini kini untuk memberitahu An...</td>\n",
       "      <td>Saya mengingatkan diri saya.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Goa Langse ini lokasinya eksotis, di pinggiran...</td>\n",
       "      <td>Goa Langse berada di pinggir tebing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>Tahun 2017, kompetisi sepak bola profesional t...</td>\n",
       "      <td>Edy Rahmayadi tidak membawahi Liga 1.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>Kawasan tempat wisata Wonosobo ini menawarkan ...</td>\n",
       "      <td>Kawasan Tempat wisata Wonosobo menawarkan 37 o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>Film ini akan menampilkan adegan laga inovatif...</td>\n",
       "      <td>Film non-laga tersebut diproduksi koreografer ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>Nebula adalah awan debu dan gas antarbintang y...</td>\n",
       "      <td>Nebula tidak mungkin terbentuk dari supernova.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>Bintang ini berada pada jarak 528 tahun cahaya...</td>\n",
       "      <td>Bintang ini berada pada jarak lebih dari 500 t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2197 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "0     Beberapa analis telah menyarankan bahwa Huawai...   \n",
       "1     \"Seperti film laga, kolosal,\" ujar aktris 33 t...   \n",
       "2     Untuk video, Air 2 bisa merekam video 4K 60fps...   \n",
       "3     Saya menulis hal ini kini untuk memberitahu An...   \n",
       "4     Goa Langse ini lokasinya eksotis, di pinggiran...   \n",
       "...                                                 ...   \n",
       "2192  Tahun 2017, kompetisi sepak bola profesional t...   \n",
       "2193  Kawasan tempat wisata Wonosobo ini menawarkan ...   \n",
       "2194  Film ini akan menampilkan adegan laga inovatif...   \n",
       "2195  Nebula adalah awan debu dan gas antarbintang y...   \n",
       "2196  Bintang ini berada pada jarak 528 tahun cahaya...   \n",
       "\n",
       "                                             hypothesis  label  \n",
       "0                     Beberapa analis mendukung Huawei.      0  \n",
       "1              Aktris itu biasa bermain pada film laga.      1  \n",
       "2                Air 2 dapat merekam video dengan baik.      1  \n",
       "3                          Saya mengingatkan diri saya.      0  \n",
       "4                  Goa Langse berada di pinggir tebing.      0  \n",
       "...                                                 ...    ...  \n",
       "2192              Edy Rahmayadi tidak membawahi Liga 1.      2  \n",
       "2193  Kawasan Tempat wisata Wonosobo menawarkan 37 o...      0  \n",
       "2194  Film non-laga tersebut diproduksi koreografer ...      2  \n",
       "2195     Nebula tidak mungkin terbentuk dari supernova.      2  \n",
       "2196  Bintang ini berada pada jarak lebih dari 500 t...      1  \n",
       "\n",
       "[2197 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_valid_t = pd.DataFrame()\n",
    "df_valid_t[\"premise\"] = df_valid[\"premise\"]\n",
    "df_valid_t[\"hypothesis\"] = df_valid[\"hypothesis\"]\n",
    "df_valid_t[\"label\"] = df_valid[\"label\"]\n",
    "df_valid_t = df_valid_t.sample(frac=1).reset_index(drop=True)\n",
    "display(df_valid_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.924340Z",
     "iopub.status.busy": "2023-07-17T19:05:09.924027Z",
     "iopub.status.idle": "2023-07-17T19:05:09.934836Z",
     "shell.execute_reply": "2023-07-17T19:05:09.933516Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.924313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count per class valid:\n",
      "0    807\n",
      "2    749\n",
      "1    641\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Count per class valid:\") \n",
    "print(df_valid_t['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.937941Z",
     "iopub.status.busy": "2023-07-17T19:05:09.936738Z",
     "iopub.status.idle": "2023-07-17T19:05:09.961051Z",
     "shell.execute_reply": "2023-07-17T19:05:09.959883Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.937856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isu akan bandara kedua untuk Sydney muncul lag...</td>\n",
       "      <td>Pemerintahan Rudd terpilih pada tahun 2011.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Selama November 2011, Paramount merilis sebuah...</td>\n",
       "      <td>Paramount tidak pernah mempromosikan hasil ril...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Larson terlihat berada di lokasi syuting, deng...</td>\n",
       "      <td>Larson menolak untuk difoto.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Saya berharap, bisa kembali lagi ke sini,\" tu...</td>\n",
       "      <td>Dia berharap dapat kembali lagi ke sini.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Posisi Bukittinggi ada di tepi Ngarai Sianok d...</td>\n",
       "      <td>Gunung Singgalang dan Gunung Marapi bukan gunu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>Menurut NASA (lembaga antariksa Amerika Serika...</td>\n",
       "      <td>Suhu terpanas pertama dicatat pada tahun 1851.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>Sindang Barang merupakan sebuah kampung budaya...</td>\n",
       "      <td>Banyak kampung budaya selain Sindang Barang.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>Makmur merupakan salah satu desa yang ada di K...</td>\n",
       "      <td>Tidak ada desa yang bernama Makmur di Riau.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>Di banyak negara, Gereja Baptis tidak bergabun...</td>\n",
       "      <td>Gereja Nasional merupakan Gereja Baptis.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>Wonder Woman juga tercatat sebagai blockbuster...</td>\n",
       "      <td>Wonder Woman merupakan film dengan budget tinggi.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "0     Isu akan bandara kedua untuk Sydney muncul lag...   \n",
       "1     Selama November 2011, Paramount merilis sebuah...   \n",
       "2     Larson terlihat berada di lokasi syuting, deng...   \n",
       "3     \"Saya berharap, bisa kembali lagi ke sini,\" tu...   \n",
       "4     Posisi Bukittinggi ada di tepi Ngarai Sianok d...   \n",
       "...                                                 ...   \n",
       "2196  Menurut NASA (lembaga antariksa Amerika Serika...   \n",
       "2197  Sindang Barang merupakan sebuah kampung budaya...   \n",
       "2198  Makmur merupakan salah satu desa yang ada di K...   \n",
       "2199  Di banyak negara, Gereja Baptis tidak bergabun...   \n",
       "2200  Wonder Woman juga tercatat sebagai blockbuster...   \n",
       "\n",
       "                                             hypothesis  label  \n",
       "0           Pemerintahan Rudd terpilih pada tahun 2011.      1  \n",
       "1     Paramount tidak pernah mempromosikan hasil ril...      2  \n",
       "2                          Larson menolak untuk difoto.      2  \n",
       "3              Dia berharap dapat kembali lagi ke sini.      0  \n",
       "4     Gunung Singgalang dan Gunung Marapi bukan gunu...      2  \n",
       "...                                                 ...    ...  \n",
       "2196     Suhu terpanas pertama dicatat pada tahun 1851.      2  \n",
       "2197       Banyak kampung budaya selain Sindang Barang.      1  \n",
       "2198        Tidak ada desa yang bernama Makmur di Riau.      2  \n",
       "2199           Gereja Nasional merupakan Gereja Baptis.      2  \n",
       "2200  Wonder Woman merupakan film dengan budget tinggi.      1  \n",
       "\n",
       "[2201 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_t = pd.DataFrame()\n",
    "df_test_t[\"premise\"] = df_test[\"premise\"]\n",
    "df_test_t[\"hypothesis\"] = df_test[\"hypothesis\"]\n",
    "df_test_t[\"label\"] = df_test[\"label\"]\n",
    "df_test_t = df_test_t.sample(frac=1).reset_index(drop=True)\n",
    "display(df_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.962787Z",
     "iopub.status.busy": "2023-07-17T19:05:09.962474Z",
     "iopub.status.idle": "2023-07-17T19:05:09.971121Z",
     "shell.execute_reply": "2023-07-17T19:05:09.969854Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.962760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count per class test:\n",
      "0    808\n",
      "2    764\n",
      "1    629\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Count per class test:\") \n",
    "print(df_test_t['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:09.974522Z",
     "iopub.status.busy": "2023-07-17T19:05:09.973431Z",
     "iopub.status.idle": "2023-07-17T19:05:10.867940Z",
     "shell.execute_reply": "2023-07-17T19:05:10.866791Z",
     "shell.execute_reply.started": "2023-07-17T19:05:09.974478Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = XLMRobertaTokenizer.from_pretrained(TOKENIZER_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:10.869991Z",
     "iopub.status.busy": "2023-07-17T19:05:10.869602Z",
     "iopub.status.idle": "2023-07-17T19:05:10.883435Z",
     "shell.execute_reply": "2023-07-17T19:05:10.881775Z",
     "shell.execute_reply.started": "2023-07-17T19:05:10.869955Z"
    }
   },
   "outputs": [],
   "source": [
    "class CompDataset(Dataset):\n",
    "    def __init__(self, df_teacher, df_student):\n",
    "        self.df_data_teacher = df_teacher\n",
    "        self.df_data_student = df_student\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Teacher\n",
    "        sentence_teacher_1 = self.df_data_teacher.loc[index, 'premise']\n",
    "        sentence_teacher_2 = self.df_data_teacher.loc[index, 'hypothesis']\n",
    "        \n",
    "        encoded_dict_teacher = tokenizer.encode_plus(\n",
    "            sentence_teacher_1,\n",
    "            sentence_teacher_2,\n",
    "            add_special_tokens = True,\n",
    "            max_length = MAX_LEN,\n",
    "            truncation='longest_first',\n",
    "            padding = 'max_length',\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt'\n",
    "        )\n",
    "        \n",
    "        padded_token_list_teacher = encoded_dict_teacher['input_ids'][0]\n",
    "        att_mask_teacher = encoded_dict_teacher['attention_mask'][0]\n",
    "        \n",
    "        target_teacher = torch.tensor([self.df_data_teacher.loc[index, 'label']])\n",
    "        lt_target_teacher = torch.LongTensor(target_teacher)\n",
    "        onehot_encoded_lbl_teacher = F.one_hot(lt_target_teacher, num_classes=3) # 3 classes: entails, neutral, contradict\n",
    "        \n",
    "        # Student\n",
    "        sentence_student_1 = self.df_data_student.loc[index, 'premise']\n",
    "        sentence_student_2 = self.df_data_student.loc[index, 'hypothesis']\n",
    "        \n",
    "        encoded_dict_student = tokenizer.encode_plus(\n",
    "            sentence_student_1,\n",
    "            sentence_student_2,\n",
    "            add_special_tokens = True,\n",
    "            max_length = MAX_LEN,\n",
    "            truncation='longest_first',\n",
    "            padding = 'max_length',\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt'\n",
    "        )\n",
    "        \n",
    "        padded_token_list_student = encoded_dict_student['input_ids'][0]\n",
    "        att_mask_student = encoded_dict_student['attention_mask'][0]\n",
    "        \n",
    "        target_student = torch.tensor([self.df_data_student.loc[index, 'label']])\n",
    "        lt_target_student = torch.LongTensor(target_student)\n",
    "        onehot_encoded_lbl_student = F.one_hot(lt_target_student, num_classes=3) # 3 classes: entails, neutral, contradict\n",
    "        \n",
    "        output = {\n",
    "            \"input_ids_teacher\": padded_token_list_teacher, \n",
    "            \"attention_mask_teacher\": att_mask_teacher,\n",
    "            \"lbl_teacher\": onehot_encoded_lbl_teacher,\n",
    "            \"input_ids_student\": padded_token_list_student, \n",
    "            \"attention_mask_student\": att_mask_student,\n",
    "            \"lbl_student\": onehot_encoded_lbl_student\n",
    "        }\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df_data_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:10.886081Z",
     "iopub.status.busy": "2023-07-17T19:05:10.885325Z",
     "iopub.status.idle": "2023-07-17T19:05:10.900169Z",
     "shell.execute_reply": "2023-07-17T19:05:10.899163Z",
     "shell.execute_reply.started": "2023-07-17T19:05:10.886044Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_cmp = CompDataset(df_train_t, df_train_student)\n",
    "valid_data_cmp = CompDataset(df_valid_t, df_valid_student)\n",
    "test_data_cmp = CompDataset(df_test_t, df_test_student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:10.902465Z",
     "iopub.status.busy": "2023-07-17T19:05:10.901730Z",
     "iopub.status.idle": "2023-07-17T19:05:10.914276Z",
     "shell.execute_reply": "2023-07-17T19:05:10.913159Z",
     "shell.execute_reply.started": "2023-07-17T19:05:10.902411Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data_cmp, batch_size = BATCH_SIZE)\n",
    "valid_dataloader = DataLoader(valid_data_cmp, batch_size = BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_data_cmp, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning model as per Bandyopadhyay, D., et al (2022) paper, but using XLMR instead of mBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:10.916643Z",
     "iopub.status.busy": "2023-07-17T19:05:10.916004Z",
     "iopub.status.idle": "2023-07-17T19:05:10.938021Z",
     "shell.execute_reply": "2023-07-17T19:05:10.936756Z",
     "shell.execute_reply.started": "2023-07-17T19:05:10.916604Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransferLearningPaper(PreTrainedModel):\n",
    "    def __init__(self, config, lambda_kld, learningrate_student, batchnorm_epsilon = 1e-5):\n",
    "        super(TransferLearningPaper, self).__init__(config)\n",
    "        \n",
    "        self.xlmr_model_teacher = XLMRobertaModel.from_pretrained(\n",
    "            MODEL_TEACHER_TYPE, # using pretrained mBERT in INA language\n",
    "            num_labels = 3,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        \n",
    "        # Freeze teacher mBERT parameters\n",
    "        for params_teacher in self.xlmr_model_teacher.parameters():\n",
    "            params_teacher.requires_grad = False\n",
    "    \n",
    "        self.xlmr_model_student = XLMRobertaModel.from_pretrained(\n",
    "            MBERT_TYPE,\n",
    "            num_labels = 3,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        \n",
    "        # Unfreeze student mBERT parameters\n",
    "        for params_student in self.xlmr_model_student.parameters():\n",
    "            params_student.requires_grad = True\n",
    "        \n",
    "        self.optimizer_student = AdamW(\n",
    "            self.xlmr_model_student.parameters(), \n",
    "            lr=learningrate_student\n",
    "        )\n",
    "        \n",
    "        self.linear = nn.Linear(config.hidden_size, 3)  # Linear layer\n",
    "        self.batchnorm = nn.BatchNorm1d(config.hidden_size, eps=batchnorm_epsilon)\n",
    "        self.softmax = nn.Softmax(dim=1)  # Softmax activation\n",
    "        \n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "        self.kld = nn.KLDivLoss(reduction='batchmean')\n",
    "        \n",
    "        # Initialize the weights of the linear layer\n",
    "        self.linear.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        self.linear.bias.data.zero_()\n",
    "        \n",
    "        self.lambda_kld = lambda_kld\n",
    "    \n",
    "    def forward(self, input_ids_teacher, attention_mask_teacher, lbl_teacher, input_ids_student, attention_mask_student, lbl_student):\n",
    "        # the label is already one-hot encoded \n",
    "        self.xlmr_model_teacher.eval()\n",
    "        self.xlmr_model_student.eval()\n",
    "        \n",
    "        lbl_teacher = lbl_teacher[:, 0, :]\n",
    "        lbl_student = lbl_student[:, 0, :]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Taking CLS token out of XLMR last hidden state\n",
    "            outputs_teacher = self.xlmr_model_teacher(\n",
    "                input_ids=input_ids_teacher, \n",
    "                attention_mask=attention_mask_teacher\n",
    "            )\n",
    "        \n",
    "            # take CLS token of the last hidden state\n",
    "            pooled_output_teacher = outputs_teacher.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # taking CLS token out of the student data without deleting the gradient\n",
    "        outputs_student = self.xlmr_model_student(\n",
    "            input_ids=input_ids_student, \n",
    "            attention_mask=attention_mask_student \n",
    "        )\n",
    "        \n",
    "        pooled_output_student = outputs_student.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # FFNN\n",
    "        batchnormed_logits = self.batchnorm(pooled_output_student)\n",
    "        linear_output = self.linear(batchnormed_logits) # the output's logits\n",
    "        softmax_linear_output = F.log_softmax(linear_output, dim=1)\n",
    "        \n",
    "        lbl_student = lbl_student.float()\n",
    "        softmax_linear_output = softmax_linear_output.float()\n",
    "        \n",
    "        # Loss Computation\n",
    "        cross_entropy_loss = self.cross_entropy(softmax_linear_output, lbl_student)\n",
    "        total_kld = self.kld(F.log_softmax(pooled_output_student, dim=1), F.softmax(pooled_output_teacher, dim=1))\n",
    "        joint_loss = cross_entropy_loss + (self.lambda_kld * total_kld )\n",
    "        \n",
    "        return {\"loss\": joint_loss, \"logits\": softmax_linear_output}\n",
    "    \n",
    "    def clear_grad(self):\n",
    "        self.xlmr_model_student.train()\n",
    "        self.optimizer_student.zero_grad()\n",
    "    \n",
    "    def backpro_compute(self, loss):\n",
    "        loss.backward()\n",
    "        \n",
    "    def update_std_weights_and_clear_grad(self):\n",
    "        self.optimizer_student.step()\n",
    "        self.optimizer_student.zero_grad()\n",
    "    \n",
    "    def update_std_weights(self):\n",
    "        self.optimizer_student.step()\n",
    "    \n",
    "    def update_param_student_model(self, loss):\n",
    "        # Doing customized backpropagation for student's model\n",
    "        self.xlmr_model_student.train()\n",
    "        \n",
    "        self.optimizer_student.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer_student.step()\n",
    "        \n",
    "    def upload_to_huggingface(self):\n",
    "        self.xlmr_model_student.push_to_hub(HF_MODEL_NAME)\n",
    "        tokenizer.push_to_hub(HF_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-17T19:05:10.941564Z",
     "iopub.status.busy": "2023-07-17T19:05:10.940365Z",
     "iopub.status.idle": "2023-07-17T19:05:26.660171Z",
     "shell.execute_reply": "2023-07-17T19:05:26.657092Z",
     "shell.execute_reply.started": "2023-07-17T19:05:10.941522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PretrainedConfig {\n",
      "  \"_name_or_path\": \"indojavanesenli-transfer-learning\",\n",
      "  \"finetuning_task\": \"indonesian-javanese natural language inference\",\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"ENTAIL\",\n",
      "    \"1\": \"NEUTRAL\",\n",
      "    \"2\": \"CONTRADICTION\"\n",
      "  },\n",
      "  \"label2id\": {\n",
      "    \"CONTRADICTION\": 2,\n",
      "    \"ENTAIL\": 0,\n",
      "    \"NEUTRAL\": 1\n",
      "  },\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.30.2\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at jalaluddin94/xlmr-nli-indoindo were not used when initializing XLMRobertaModel: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at jalaluddin94/xlmr-nli-indoindo and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">25</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>learningrate_student = STUDENT_LRATE,                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>batchnorm_epsilon = BATCH_NORM_EPSILON                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24 </span>)                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>25 transferlearning_model = transferlearning_model.to(device)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1902</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1899 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1900 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().to(*args, **kwargs)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1901 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1902 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">half</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args):                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1903 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Checks if the model has been loaded in 8-bit</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1904 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"is_quantized\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1905 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1145</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1142 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>non_blocking, memory_format=convert_to_format)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1143 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">No</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1145 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._apply(convert)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1146 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1147 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">register_full_backward_pre_hook</span>(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1148 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>,                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">797</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 794 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 795 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 796 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 797 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 798 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 799 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 800 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">797</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 794 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 795 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 796 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 797 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 798 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 799 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 800 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">797</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 794 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 795 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 796 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 797 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 798 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 799 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 800 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">820</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 817 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># track autograd history of `param_applied`, so we have to use</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 818 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># `with torch.no_grad():`</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 819 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 820 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>param_applied = fn(param)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 821 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>should_use_set_data = compute_should_use_set_data(param, param_applied)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 822 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> should_use_set_data:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 823 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>param.data = param_applied                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1143</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">convert</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1140 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> convert_to_format <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> t.dim() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>):                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">els</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1142 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>non_blocking, memory_format=convert_to_format)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1143 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">No</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1145 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._apply(convert)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1146 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">734.00</span> MiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.90</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.51</span> GiB \n",
       "already allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">371.75</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.65</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated \n",
       "memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m25\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m22 \u001b[0m\u001b[2m│   \u001b[0mlearningrate_student = STUDENT_LRATE,                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2m│   \u001b[0mbatchnorm_epsilon = BATCH_NORM_EPSILON                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m24 \u001b[0m)                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m25 transferlearning_model = transferlearning_model.to(device)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m26 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mmodeling_utils.py\u001b[0m:\u001b[94m1902\u001b[0m in \u001b[92mto\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1899 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1900 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96msuper\u001b[0m().to(*args, **kwargs)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1901 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1902 \u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mhalf\u001b[0m(\u001b[96mself\u001b[0m, *args):                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1903 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Checks if the model has been loaded in 8-bit\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1904 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mgetattr\u001b[0m(\u001b[96mself\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mis_quantized\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mFalse\u001b[0m):                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1905 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1145\u001b[0m in \u001b[92mto\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1142 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mnon_blocking, memory_format=convert_to_format)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1143 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m t.to(device, dtype \u001b[94mif\u001b[0m t.is_floating_point() \u001b[95mor\u001b[0m t.is_complex() \u001b[94melse\u001b[0m \u001b[94mNo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1144 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1145 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._apply(convert)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1146 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1147 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mregister_full_backward_pre_hook\u001b[0m(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1148 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m,                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m797\u001b[0m in \u001b[92m_apply\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 794 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 795 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 796 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 797 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 798 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 799 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 800 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m797\u001b[0m in \u001b[92m_apply\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 794 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 795 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 796 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 797 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 798 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 799 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 800 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m797\u001b[0m in \u001b[92m_apply\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 794 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 795 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 796 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 797 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 798 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 799 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 800 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m820\u001b[0m in \u001b[92m_apply\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 817 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# track autograd history of `param_applied`, so we have to use\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 818 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# `with torch.no_grad():`\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 819 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 820 \u001b[2m│   │   │   │   \u001b[0mparam_applied = fn(param)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 821 \u001b[0m\u001b[2m│   │   │   \u001b[0mshould_use_set_data = compute_should_use_set_data(param, param_applied)       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 822 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m should_use_set_data:                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 823 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mparam.data = param_applied                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1143\u001b[0m in \u001b[92mconvert\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1140 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m convert_to_format \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m t.dim() \u001b[95min\u001b[0m (\u001b[94m4\u001b[0m, \u001b[94m5\u001b[0m):                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1141 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m t.to(device, dtype \u001b[94mif\u001b[0m t.is_floating_point() \u001b[95mor\u001b[0m t.is_complex() \u001b[94mels\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1142 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mnon_blocking, memory_format=convert_to_format)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1143 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m t.to(device, dtype \u001b[94mif\u001b[0m t.is_floating_point() \u001b[95mor\u001b[0m t.is_complex() \u001b[94melse\u001b[0m \u001b[94mNo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1144 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1145 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._apply(convert)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1146 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m734.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m15.90\u001b[0m GiB total capacity; \u001b[1;36m13.51\u001b[0m GiB \n",
       "already allocated; \u001b[1;36m371.75\u001b[0m MiB free; \u001b[1;36m14.65\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated \n",
       "memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = PretrainedConfig(\n",
    "    problem_type = \"single_label_classification\",\n",
    "    id2label = {\n",
    "        \"0\": \"ENTAIL\",\n",
    "        \"1\": \"NEUTRAL\",\n",
    "        \"2\": \"CONTRADICTION\"\n",
    "    },\n",
    "    label2id = {\n",
    "        \"ENTAIL\": 0,\n",
    "        \"NEUTRAL\": 1,\n",
    "        \"CONTRADICTION\": 2\n",
    "    },\n",
    "    num_labels = 3,\n",
    "    hidden_size = 768,\n",
    "    name_or_path = \"indojavanesenli-transfer-learning\",\n",
    "    finetuning_task = \"indonesian-javanese natural language inference\"\n",
    ")\n",
    "print(config)\n",
    "transferlearning_model = TransferLearningPaper(\n",
    "    config = config,\n",
    "    lambda_kld = LAMBDA_KLD, # antara 0.01-0.5\n",
    "    learningrate_student = STUDENT_LRATE,\n",
    "    batchnorm_epsilon = BATCH_NORM_EPSILON\n",
    ")\n",
    "transferlearning_model = transferlearning_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-17T19:05:26.661955Z",
     "iopub.status.idle": "2023-07-17T19:05:26.662509Z",
     "shell.execute_reply": "2023-07-17T19:05:26.662240Z",
     "shell.execute_reply.started": "2023-07-17T19:05:26.662214Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-17T19:05:26.664780Z",
     "iopub.status.idle": "2023-07-17T19:05:26.665321Z",
     "shell.execute_reply": "2023-07-17T19:05:26.665058Z",
     "shell.execute_reply.started": "2023-07-17T19:05:26.665032Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    labels = np.argmax(labels[:,0,:], axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average='micro')\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average='micro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average='weighted')\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1_score\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-17T19:05:26.667579Z",
     "iopub.status.idle": "2023-07-17T19:05:26.668151Z",
     "shell.execute_reply": "2023-07-17T19:05:26.667868Z",
     "shell.execute_reply.started": "2023-07-17T19:05:26.667842Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(the_model, train_data, pgb):\n",
    "    the_model.train()\n",
    "    \n",
    "    batch_loss = 0\n",
    "    \n",
    "    for batch, data in enumerate(train_data):\n",
    "        # Clear accumulated gradients\n",
    "        the_model.clear_grad()\n",
    "        \n",
    "        input_ids_teacher = data[\"input_ids_teacher\"].to(device)\n",
    "        attention_mask_teacher = data[\"attention_mask_teacher\"].to(device)\n",
    "        lbl_teacher = data[\"lbl_teacher\"].to(device)\n",
    "        input_ids_student = data[\"input_ids_student\"].to(device)\n",
    "        attention_mask_student = data[\"attention_mask_student\"].to(device)\n",
    "        lbl_student = data[\"lbl_student\"].to(device)\n",
    "        \n",
    "        output = the_model(\n",
    "            input_ids_teacher = input_ids_teacher, \n",
    "            attention_mask_teacher = attention_mask_teacher,\n",
    "            lbl_teacher = lbl_teacher,\n",
    "            input_ids_student = input_ids_student, \n",
    "            attention_mask_student = attention_mask_student, \n",
    "            lbl_student = lbl_student\n",
    "        )\n",
    "        \n",
    "        loss_model = output[\"loss\"]\n",
    "        batch_loss += loss_model\n",
    "        \n",
    "        # Backpropagation\n",
    "        # the_model.update_param_student_model(loss_model) # uncomment to use ordinary backpro\n",
    "        ## now using gradient accumulation technique\n",
    "        the_model.backpro_compute(loss_model) # backward pass and gradient accumulation\n",
    "        \n",
    "        # Accumulate gradients for the desired number of mini-batches\n",
    "        if(batch+1) % BATCH_SIZE == 0:\n",
    "            # update weights\n",
    "            the_model.update_std_weights_and_clear_grad()\n",
    "        \n",
    "        pgb.update(1 / len(train_data))\n",
    "    \n",
    "    # Make sure to update the weights for any remaining accumulated gradients\n",
    "    if (batch+1) % BATCH_SIZE != 0:\n",
    "        the_model.update_std_weights()\n",
    "        \n",
    "    training_loss = batch_loss / BATCH_SIZE\n",
    "    wandb.log({\"train/loss\": training_loss})\n",
    "    \n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-17T19:05:26.671902Z",
     "iopub.status.idle": "2023-07-17T19:05:26.672436Z",
     "shell.execute_reply": "2023-07-17T19:05:26.672167Z",
     "shell.execute_reply.started": "2023-07-17T19:05:26.672142Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(the_model, valid_data):\n",
    "    the_model.eval()\n",
    "    \n",
    "    batch_loss = 0\n",
    "    \n",
    "    eval_f1 = []\n",
    "    eval_accuracy = []\n",
    "    eval_precision = []\n",
    "    eval_recall = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, data in enumerate(valid_data):\n",
    "            input_ids_teacher = data[\"input_ids_teacher\"].to(device)\n",
    "            attention_mask_teacher = data[\"attention_mask_teacher\"].to(device)\n",
    "            lbl_teacher = data[\"lbl_teacher\"].to(device)\n",
    "            input_ids_student = data[\"input_ids_student\"].to(device)\n",
    "            attention_mask_student = data[\"attention_mask_student\"].to(device)\n",
    "            lbl_student = data[\"lbl_student\"].to(device)\n",
    "\n",
    "            output = the_model(\n",
    "                input_ids_teacher = input_ids_teacher, \n",
    "                attention_mask_teacher = attention_mask_teacher, \n",
    "                lbl_teacher = lbl_teacher,\n",
    "                input_ids_student = input_ids_student, \n",
    "                attention_mask_student = attention_mask_student,\n",
    "                lbl_student = lbl_student\n",
    "            )\n",
    "\n",
    "            logits = output[\"logits\"].cpu().detach().numpy()\n",
    "            packed_val = logits, lbl_student.cpu().detach().numpy()\n",
    "            metrics = compute_metrics(packed_val)\n",
    "            \n",
    "            eval_f1.append(metrics[\"f1_score\"])\n",
    "            eval_accuracy.append(metrics[\"accuracy\"])\n",
    "            eval_precision.append(metrics[\"precision\"])\n",
    "            eval_recall.append(metrics[\"recall\"])\n",
    "            \n",
    "            loss_model = output[\"loss\"]\n",
    "            batch_loss += loss_model\n",
    "    \n",
    "        eval_loss = batch_loss / BATCH_SIZE\n",
    "        wandb.log({\n",
    "            \"eval/loss\": eval_loss, \n",
    "            \"eval/f1_score\": np.average(eval_f1), \n",
    "            \"eval/accuracy\": np.average(eval_accuracy),\n",
    "            \"eval/precision\": np.average(eval_precision),\n",
    "            \"eval/recall\": np.average(eval_recall)\n",
    "        })\n",
    "    \n",
    "    out_metrics = {\n",
    "        \"eval/loss\": eval_loss, \n",
    "        \"eval/f1_score\": np.average(eval_f1), \n",
    "        \"eval/accuracy\": np.average(eval_accuracy),\n",
    "        \"eval/precision\": np.average(eval_precision),\n",
    "        \"eval/recall\": np.average(eval_recall)\n",
    "    }\n",
    "    \n",
    "    return eval_loss, out_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-17T19:05:26.674596Z",
     "iopub.status.idle": "2023-07-17T19:05:26.675156Z",
     "shell.execute_reply": "2023-07-17T19:05:26.674912Z",
     "shell.execute_reply.started": "2023-07-17T19:05:26.674885Z"
    }
   },
   "outputs": [],
   "source": [
    "def training_sequence(the_model, train_data, valid_data, epochs):\n",
    "    track_train_loss = []\n",
    "    track_val_loss = []\n",
    "    \n",
    "    pbar_format = \"{l_bar}{bar} | Epoch: {n:.2f}/{total_fmt} [{elapsed}<{remaining}]\"\n",
    "    with tqdm(total=epochs, colour=\"blue\", leave=True, position=0, bar_format=pbar_format) as t:\n",
    "        for ep in range(epochs):\n",
    "            training_loss = train(the_model, train_data, t)\n",
    "            t.set_description(f\"Evaluating... Train loss: {training_loss:.3f}\")\n",
    "            valid_loss, _ = validate(the_model, valid_data)\n",
    "\n",
    "            track_train_loss.append(training_loss)\n",
    "            track_val_loss.append(valid_loss)\n",
    "\n",
    "            t.set_description(f\"Train loss: {training_loss:.3f} Valid loss: {valid_loss:.3f}\")\n",
    "\n",
    "            if valid_loss < min(track_val_loss) or ep + 1 == 1:\n",
    "                the_model.save_pretrained(\n",
    "                    save_directory = MODEL_PATH + \"indojavanesenli-transfer-learning\"\n",
    "                )\n",
    "\n",
    "            wandb.log({\n",
    "                \"train_loss/epoch\": training_loss,\n",
    "                \"validation_loss/epoch\": valid_loss\n",
    "            })\n",
    "        \n",
    "    return {\n",
    "        \"training_loss\": track_train_loss,\n",
    "        \"validation_loss\": track_val_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-17T19:05:26.677231Z",
     "iopub.status.idle": "2023-07-17T19:05:26.677764Z",
     "shell.execute_reply": "2023-07-17T19:05:26.677503Z",
     "shell.execute_reply.started": "2023-07-17T19:05:26.677480Z"
    }
   },
   "outputs": [],
   "source": [
    "training_result = training_sequence(transferlearning_model, train_dataloader, valid_dataloader, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-17T19:05:26.682656Z",
     "iopub.status.idle": "2023-07-17T19:05:26.683192Z",
     "shell.execute_reply": "2023-07-17T19:05:26.682948Z",
     "shell.execute_reply.started": "2023-07-17T19:05:26.682921Z"
    }
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transferlearning_model.upload_to_huggingface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
