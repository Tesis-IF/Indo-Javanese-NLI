{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install -U scikit-learn\n! pip install wandb\n! pip install tqdm\n! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n! pip install -U git+https://github.com/huggingface/transformers.git\n! pip install -U git+https://github.com/huggingface/accelerate.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-17T19:03:17.150727Z","iopub.execute_input":"2023-07-17T19:03:17.151113Z","iopub.status.idle":"2023-07-17T19:05:09.497402Z","shell.execute_reply.started":"2023-07-17T19:03:17.151083Z","shell.execute_reply":"2023-07-17T19:05:09.496101Z"},"trusted":true},"execution_count":263,"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.3.0)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\nRequirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.5)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.3)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.27.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (59.8.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.65.0)\nLooking in indexes: https://download.pytorch.org/whl/cu117\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nCollecting git+https://github.com/huggingface/transformers.git\n  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-fjri10qj\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-fjri10qj\n  Resolved https://github.com/huggingface/transformers.git to commit 9dc965bb404c2bb8e3c02eaa5eea6502af1aee1a\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (4.65.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.32.0.dev0) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.32.0.dev0) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.32.0.dev0) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (2023.5.7)\nCollecting git+https://github.com/huggingface/accelerate.git\n  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-oz0zl5aj\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-oz0zl5aj\n  Resolved https://github.com/huggingface/accelerate.git to commit 653ba110d31c86d3527bb88bf6209441c176ce11\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0.dev0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0.dev0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0.dev0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0.dev0) (6.0)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0.dev0) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.22.0.dev0) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.22.0.dev0) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.22.0.dev0) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport gc\nimport random\nimport time\nfrom tqdm import tqdm, trange\n\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# set a seed value\ntorch.manual_seed(42)\n\nfrom datasets import load_dataset\n\nimport wandb\n\nimport transformers\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import AdamW, EarlyStoppingCallback\nfrom transformers import PreTrainedModel, PretrainedConfig\nfrom transformers import XLMRobertaModel, XLMRobertaForSequenceClassification, XLMRobertaTokenizer\nfrom huggingface_hub import login","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.500433Z","iopub.execute_input":"2023-07-17T19:05:09.501622Z","iopub.status.idle":"2023-07-17T19:05:09.512657Z","shell.execute_reply.started":"2023-07-17T19:05:09.501579Z","shell.execute_reply":"2023-07-17T19:05:09.511116Z"},"trusted":true},"execution_count":264,"outputs":[]},{"cell_type":"code","source":"TOKENIZER_TYPE = 'xlm-roberta-base'\nMBERT_TYPE = 'xlm-roberta-base'\nMODEL_TEACHER_TYPE = 'jalaluddin94/xlmr-nli-indoindo'\nMODEL_PATH = '/kaggle/working/ResearchedModels/'\nHF_MODEL_NAME = 'jalaluddin94/trf-learning-indojavanesenli-xlmr'\n\nSTUDENT_LRATE = 2e-5\nLAMBDA_KLD = 0.5 # between 0.01 - 0.5\nMAX_LEN = 512\nNUM_EPOCHS = 5\nBATCH_SIZE = 1\nBATCH_NORM_EPSILON = 1e-5\nLAMBDA_L2 = 3e-5\n\nHF_TOKEN = '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'\n\nNUM_CORES = os.cpu_count() - 2","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.514198Z","iopub.execute_input":"2023-07-17T19:05:09.514696Z","iopub.status.idle":"2023-07-17T19:05:09.528822Z","shell.execute_reply.started":"2023-07-17T19:05:09.514654Z","shell.execute_reply":"2023-07-17T19:05:09.527646Z"},"trusted":true},"execution_count":265,"outputs":[]},{"cell_type":"code","source":"login(token=HF_TOKEN)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %env WANDB_API_KEY=97b170d223eb55f86fe1fbf9640831ad76381a74\n# wandb.login()","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.532271Z","iopub.execute_input":"2023-07-17T19:05:09.532691Z","iopub.status.idle":"2023-07-17T19:05:09.549191Z","shell.execute_reply.started":"2023-07-17T19:05:09.532652Z","shell.execute_reply":"2023-07-17T19:05:09.548094Z"},"trusted":true},"execution_count":266,"outputs":[]},{"cell_type":"code","source":"# %env WANDB_LOG_MODEL='end'\n# run = wandb.init(\n#   project=\"javanese_nli\",\n#   notes=\"Experiment transfer learning on Bandyopadhyay's paper using XLMR\",\n#   name=\"trf-lrn-experiment-xlmr-epoch5-lamdakld0.5\",\n#   tags=[\"transferlearning\", \"bandyopadhyay\", \"xlmr\"]\n# )","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.551198Z","iopub.execute_input":"2023-07-17T19:05:09.551695Z","iopub.status.idle":"2023-07-17T19:05:09.562505Z","shell.execute_reply.started":"2023-07-17T19:05:09.551657Z","shell.execute_reply":"2023-07-17T19:05:09.561414Z"},"trusted":true},"execution_count":267,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_AGENT_MAX_INITIAL_FAILURES\"]=\"1024\"\nos.environ[\"WANDB_AGENT_DISABLE_FLAPPING\"]=\"true\"","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.564339Z","iopub.execute_input":"2023-07-17T19:05:09.565157Z","iopub.status.idle":"2023-07-17T19:05:09.576350Z","shell.execute_reply.started":"2023-07-17T19:05:09.565117Z","shell.execute_reply":"2023-07-17T19:05:09.574636Z"},"trusted":true},"execution_count":268,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.578485Z","iopub.execute_input":"2023-07-17T19:05:09.578791Z","iopub.status.idle":"2023-07-17T19:05:09.589132Z","shell.execute_reply.started":"2023-07-17T19:05:09.578748Z","shell.execute_reply":"2023-07-17T19:05:09.588093Z"},"trusted":true},"execution_count":269,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"markdown","source":"Prepare Dataset for Student","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/dataset-indojavanesenli/indojavanesenli-train.csv\", sep='\\t')\ndf_train = df_train.sample(frac=1).reset_index(drop=True) #shuffle the data\n\ndf_train_student = pd.DataFrame()\ndf_train_student[\"premise\"] = df_train[\"premise\"]\ndf_train_student[\"hypothesis\"] = df_train[\"jv_hypothesis_mongo\"]\ndf_train_student[\"label\"] = df_train[\"label\"]\ndf_train_student.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.590783Z","iopub.execute_input":"2023-07-17T19:05:09.591459Z","iopub.status.idle":"2023-07-17T19:05:09.747569Z","shell.execute_reply.started":"2023-07-17T19:05:09.591422Z","shell.execute_reply":"2023-07-17T19:05:09.746392Z"},"trusted":true},"execution_count":270,"outputs":[{"execution_count":270,"output_type":"execute_result","data":{"text/plain":"                                             premise  \\\n0  Esai ini, yang diterbitkan sebagai Undersea, m...   \n1  \"Pada tahun 2001, Komite Olimpiade Internasion...   \n2  Hargeisa adalah kota terbesar kedua di Somalia...   \n3  Tentunya Tiongkok akan menyajikan banyak peran...   \n4  Leher nya bergerak maju dalam konfrontasi yang...   \n\n                                          hypothesis  label  \n0  esai iki ngrupakne narasi babagan dalan neng d...      0  \n1  semenjak 2001 tuan surup olimpiade uga dadi tu...      0  \n2  hargesia dhekea kutha paling gedhe neng somali...      0  \n3  durung ana rencana saka tiongkok kanggo unjuk ...      2  \n4                                   dheweke keweden.      2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Esai ini, yang diterbitkan sebagai Undersea, m...</td>\n      <td>esai iki ngrupakne narasi babagan dalan neng d...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"Pada tahun 2001, Komite Olimpiade Internasion...</td>\n      <td>semenjak 2001 tuan surup olimpiade uga dadi tu...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hargeisa adalah kota terbesar kedua di Somalia...</td>\n      <td>hargesia dhekea kutha paling gedhe neng somali...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Tentunya Tiongkok akan menyajikan banyak peran...</td>\n      <td>durung ana rencana saka tiongkok kanggo unjuk ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Leher nya bergerak maju dalam konfrontasi yang...</td>\n      <td>dheweke keweden.</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_valid = pd.read_csv(\"/kaggle/input/dataset-indojavanesenli/indojavanesenli-valid.csv\", sep='\\t')\ndf_valid = df_valid.sample(frac=1).reset_index(drop=True) #shuffle the data\n\ndf_valid_student = pd.DataFrame()\ndf_valid_student[\"premise\"] = df_valid[\"premise\"]\ndf_valid_student[\"hypothesis\"] = df_valid[\"jv_hypothesis_mongo\"]\ndf_valid_student[\"label\"] = df_valid[\"label\"]\ndf_valid_student.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.749496Z","iopub.execute_input":"2023-07-17T19:05:09.749869Z","iopub.status.idle":"2023-07-17T19:05:09.798482Z","shell.execute_reply.started":"2023-07-17T19:05:09.749834Z","shell.execute_reply":"2023-07-17T19:05:09.796267Z"},"trusted":true},"execution_count":271,"outputs":[{"execution_count":271,"output_type":"execute_result","data":{"text/plain":"                                             premise  \\\n0  Beliau adalah orang yang paling baik akhlaknya...   \n1  Liga eSport Amerika Serikat (AS), Collegiate S...   \n2  Ibu tiga anak ini juga membenarkan jika bagian...   \n3  Sekitar 23 juta orang di pesisir Indonesia dip...   \n4  Brivio yang juga pernah bekerja sama dengan Ro...   \n\n                                          hypothesis  label  \n0                    wong kuwi nduweni akhlak becik.      0  \n1  turnamen tiktok cup arep dianakne ing udhar 20...      1  \n2                     kecelakaan tol entas kedadean.      2  \n3  taun 2050 diprediksi arep dadi taun kebecikan ...      2  \n4   rossi nduweni kabisan adaptasi sing jaba biyasa.      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Beliau adalah orang yang paling baik akhlaknya...</td>\n      <td>wong kuwi nduweni akhlak becik.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Liga eSport Amerika Serikat (AS), Collegiate S...</td>\n      <td>turnamen tiktok cup arep dianakne ing udhar 20...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ibu tiga anak ini juga membenarkan jika bagian...</td>\n      <td>kecelakaan tol entas kedadean.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sekitar 23 juta orang di pesisir Indonesia dip...</td>\n      <td>taun 2050 diprediksi arep dadi taun kebecikan ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Brivio yang juga pernah bekerja sama dengan Ro...</td>\n      <td>rossi nduweni kabisan adaptasi sing jaba biyasa.</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/dataset-indojavanesenli/indojavanesenli-test.csv\", sep='\\t')\ndf_test = df_test.sample(frac=1).reset_index(drop=True) #shuffle the data\n\ndf_test_student = pd.DataFrame()\ndf_test_student[\"premise\"] = df_test[\"premise\"]\ndf_test_student[\"premise\"] = df_test_student[\"premise\"].astype(str)\ndf_test_student[\"hypothesis\"] = df_test[\"jv_hypothesis_mongo\"]\ndf_test_student[\"hypothesis\"] = df_test_student[\"hypothesis\"].astype(str)\ndf_test_student[\"label\"] = df_test[\"label\"]\ndf_test_student.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.802986Z","iopub.execute_input":"2023-07-17T19:05:09.804040Z","iopub.status.idle":"2023-07-17T19:05:09.856609Z","shell.execute_reply.started":"2023-07-17T19:05:09.803997Z","shell.execute_reply":"2023-07-17T19:05:09.855433Z"},"trusted":true},"execution_count":272,"outputs":[{"execution_count":272,"output_type":"execute_result","data":{"text/plain":"                                             premise  \\\n0  Sebagian besar pembicara menganggap ini menjad...   \n1  Middlesbrough dan Bournemouth juga gagal mempe...   \n2  GERD (Gastroesophageal Reflux Disease) adalah ...   \n3  Kalau dengan posisi ini suami mampu menahan ej...   \n4  Uni Soviet adalah negara sosialis yang pernah ...   \n\n                                          hypothesis  label  \n0  sakanggonan gedhe pangomong nganggep iki dadi ...      0  \n1           bournemouth tau rumangsakne kemumpangan.      1  \n2                  gerd marakake alangan pernapasan.      0  \n3  laki ora bisa nglakoke hubungan seksual karo p...      2  \n4                   uni soviet yaiku nagara komunis.      2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sebagian besar pembicara menganggap ini menjad...</td>\n      <td>sakanggonan gedhe pangomong nganggep iki dadi ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Middlesbrough dan Bournemouth juga gagal mempe...</td>\n      <td>bournemouth tau rumangsakne kemumpangan.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GERD (Gastroesophageal Reflux Disease) adalah ...</td>\n      <td>gerd marakake alangan pernapasan.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Kalau dengan posisi ini suami mampu menahan ej...</td>\n      <td>laki ora bisa nglakoke hubungan seksual karo p...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Uni Soviet adalah negara sosialis yang pernah ...</td>\n      <td>uni soviet yaiku nagara komunis.</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Prepare Dataset for Teacher","metadata":{}},{"cell_type":"markdown","source":"Dataset from teacher will be from \"IndoNLI\", and using Indonesian only.","metadata":{}},{"cell_type":"code","source":"df_train_t = pd.DataFrame()\ndf_train_t[\"premise\"] = df_train[\"premise\"]\ndf_train_t[\"hypothesis\"] = df_train[\"hypothesis\"]\ndf_train_t[\"label\"] = df_train[\"label\"]\ndf_train_t = df_train_t.sample(frac=1).reset_index(drop=True)\ndisplay(df_train_t)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.859268Z","iopub.execute_input":"2023-07-17T19:05:09.860244Z","iopub.status.idle":"2023-07-17T19:05:09.884890Z","shell.execute_reply.started":"2023-07-17T19:05:09.860205Z","shell.execute_reply":"2023-07-17T19:05:09.882628Z"},"trusted":true},"execution_count":273,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                 premise  \\\n0      Jonan menyampaikan pernyataan itu, menanggapi ...   \n1      Pada awal tahun 2006, mantan koordinator Kampa...   \n2      Vinales menjadi yang tercepat sepanjang dua ha...   \n3      Invasi Irak ke Kuwait disebabkan oleh kemeroso...   \n4      Dengan saran dari Alexander, ia pun bisa berko...   \n...                                                  ...   \n10325  Beragam penduduk asli mendiami Alaska selama r...   \n10326  Selera Tiongkok yang tak pernah terpuaskan ter...   \n10327  Pada tahun 1271, setelah sebulan pertempuran, ...   \n10328  Malaysia mampu membuka skor pada menit ke-11 m...   \n10329  Dalam spesifikasi Federasi Renang Internasiona...   \n\n                                              hypothesis  label  \n0      Tidak ada perubahan status kontrak karya ke iz...      2  \n1                            Ryaas Rasyid adalah ekonom.      2  \n2      Pada tes hari kedua, catatan waktu Vinales di ...      2  \n3                       Irak banyak mengalami kesulitan.      1  \n4      Ia tidak mempertimbangkan anjuran dari Alexander.      2  \n...                                                  ...    ...  \n10325  Orang Eropa telah tinggal ribuan tahun di daer...      2  \n10326    Produk KFC tidak sesuai dengan selera Tiongkok.      2  \n10327                      Baibar adalah seorang sultan.      1  \n10328  Malaysia belum mendapat skor pada menit ke-30 ...      2  \n10329  Federasi Renang Internasional menetapkan panja...      0  \n\n[10330 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Jonan menyampaikan pernyataan itu, menanggapi ...</td>\n      <td>Tidak ada perubahan status kontrak karya ke iz...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pada awal tahun 2006, mantan koordinator Kampa...</td>\n      <td>Ryaas Rasyid adalah ekonom.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Vinales menjadi yang tercepat sepanjang dua ha...</td>\n      <td>Pada tes hari kedua, catatan waktu Vinales di ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Invasi Irak ke Kuwait disebabkan oleh kemeroso...</td>\n      <td>Irak banyak mengalami kesulitan.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dengan saran dari Alexander, ia pun bisa berko...</td>\n      <td>Ia tidak mempertimbangkan anjuran dari Alexander.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10325</th>\n      <td>Beragam penduduk asli mendiami Alaska selama r...</td>\n      <td>Orang Eropa telah tinggal ribuan tahun di daer...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10326</th>\n      <td>Selera Tiongkok yang tak pernah terpuaskan ter...</td>\n      <td>Produk KFC tidak sesuai dengan selera Tiongkok.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10327</th>\n      <td>Pada tahun 1271, setelah sebulan pertempuran, ...</td>\n      <td>Baibar adalah seorang sultan.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10328</th>\n      <td>Malaysia mampu membuka skor pada menit ke-11 m...</td>\n      <td>Malaysia belum mendapat skor pada menit ke-30 ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10329</th>\n      <td>Dalam spesifikasi Federasi Renang Internasiona...</td>\n      <td>Federasi Renang Internasional menetapkan panja...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10330 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Count per class train:\") \nprint(df_train_t['label'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.886735Z","iopub.execute_input":"2023-07-17T19:05:09.887147Z","iopub.status.idle":"2023-07-17T19:05:09.896426Z","shell.execute_reply.started":"2023-07-17T19:05:09.887110Z","shell.execute_reply":"2023-07-17T19:05:09.895073Z"},"trusted":true},"execution_count":274,"outputs":[{"name":"stdout","text":"Count per class train:\n0    3476\n2    3439\n1    3415\nName: label, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"df_valid_t = pd.DataFrame()\ndf_valid_t[\"premise\"] = df_valid[\"premise\"]\ndf_valid_t[\"hypothesis\"] = df_valid[\"hypothesis\"]\ndf_valid_t[\"label\"] = df_valid[\"label\"]\ndf_valid_t = df_valid_t.sample(frac=1).reset_index(drop=True)\ndisplay(df_valid_t)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.898036Z","iopub.execute_input":"2023-07-17T19:05:09.899523Z","iopub.status.idle":"2023-07-17T19:05:09.922615Z","shell.execute_reply.started":"2023-07-17T19:05:09.899491Z","shell.execute_reply":"2023-07-17T19:05:09.920650Z"},"trusted":true},"execution_count":275,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                premise  \\\n0     Lari sambung atau lari estafet adalah salah sa...   \n1     Bagi Anda yang ingin melakukan wisata edukasi,...   \n2     Pada 1865, Kapal Uap Sultana yang mengangkut 2...   \n3     Saya menulis hal ini kini untuk memberitahu An...   \n4     Selama perang kemerdekaan RI dari 1945-1949, h...   \n...                                                 ...   \n2192  Kemudian kedua orang tua itu mencoba mengubah ...   \n2193  Bangunan ini digunakan untuk penjualan berbaga...   \n2194  \"Biarlah masyarakat bahasa memiliki kebebasan ...   \n2195  Zeltweg adalah kota yang terletak di Aichfeld ...   \n2196  Dari 1970 hingga 1974, ia tinggal bersama oran...   \n\n                                             hypothesis  label  \n0     Lari estafet dilaksanakan dengan minimal 3 orang.      1  \n1              Banyak pilihahn wisata Edukasi di Bogor.      1  \n2     Kapal Uap Sultana hanya beroperasi pada tahun ...      1  \n3                    Saya tidak mengingatkan diri saya.      2  \n4              Pejabat Belanda NICA-KNIL sangat banyak.      1  \n...                                                 ...    ...  \n2192                    Ia tidak mempunyai 2 orang tua.      2  \n2193  Pemilik dari bangunan ini adalah penguasa wila...      1  \n2194  Masyarakat tidak bebas untuk memilih menurut P...      2  \n2195              Zeltweg berada pada ketinggian 659 m.      0  \n2196  Terdapat orang Indian Embera-Wounaan yang ting...      0  \n\n[2197 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Lari sambung atau lari estafet adalah salah sa...</td>\n      <td>Lari estafet dilaksanakan dengan minimal 3 orang.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bagi Anda yang ingin melakukan wisata edukasi,...</td>\n      <td>Banyak pilihahn wisata Edukasi di Bogor.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pada 1865, Kapal Uap Sultana yang mengangkut 2...</td>\n      <td>Kapal Uap Sultana hanya beroperasi pada tahun ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Saya menulis hal ini kini untuk memberitahu An...</td>\n      <td>Saya tidak mengingatkan diri saya.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Selama perang kemerdekaan RI dari 1945-1949, h...</td>\n      <td>Pejabat Belanda NICA-KNIL sangat banyak.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2192</th>\n      <td>Kemudian kedua orang tua itu mencoba mengubah ...</td>\n      <td>Ia tidak mempunyai 2 orang tua.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2193</th>\n      <td>Bangunan ini digunakan untuk penjualan berbaga...</td>\n      <td>Pemilik dari bangunan ini adalah penguasa wila...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2194</th>\n      <td>\"Biarlah masyarakat bahasa memiliki kebebasan ...</td>\n      <td>Masyarakat tidak bebas untuk memilih menurut P...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2195</th>\n      <td>Zeltweg adalah kota yang terletak di Aichfeld ...</td>\n      <td>Zeltweg berada pada ketinggian 659 m.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2196</th>\n      <td>Dari 1970 hingga 1974, ia tinggal bersama oran...</td>\n      <td>Terdapat orang Indian Embera-Wounaan yang ting...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2197 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Count per class valid:\") \nprint(df_valid_t['label'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.924027Z","iopub.execute_input":"2023-07-17T19:05:09.924340Z","iopub.status.idle":"2023-07-17T19:05:09.934836Z","shell.execute_reply.started":"2023-07-17T19:05:09.924313Z","shell.execute_reply":"2023-07-17T19:05:09.933516Z"},"trusted":true},"execution_count":276,"outputs":[{"name":"stdout","text":"Count per class valid:\n0    807\n2    749\n1    641\nName: label, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test_t = pd.DataFrame()\ndf_test_t[\"premise\"] = df_test[\"premise\"]\ndf_test_t[\"hypothesis\"] = df_test[\"hypothesis\"]\ndf_test_t[\"label\"] = df_test[\"label\"]\ndf_test_t = df_test_t.sample(frac=1).reset_index(drop=True)\ndisplay(df_test_t)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.936738Z","iopub.execute_input":"2023-07-17T19:05:09.937941Z","iopub.status.idle":"2023-07-17T19:05:09.961051Z","shell.execute_reply.started":"2023-07-17T19:05:09.937856Z","shell.execute_reply":"2023-07-17T19:05:09.959883Z"},"trusted":true},"execution_count":277,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                premise  \\\n0     Santa Fe adalah sebuah kotamadya di Vega de Gr...   \n1     Pameran bertajuk \"Titanic—The Promise of Moder...   \n2     Misalnya, dengan dicantumkannya Hak Asasi Manu...   \n3     Konser bertajuk Cross Genre Music ini adalah g...   \n4     Pakaian formal yang dikenakan pejabat sipil (b...   \n...                                                 ...   \n2196  Mariah segera memeriksakan dirinya ke rumah sa...   \n2197  Selama curah hujan, tetesan air menyerap dan m...   \n2198  Berpetualang bersama teman di Gunung Batu Jong...   \n2199  Purwokerto Selatan adalah sebuah kecamatan di ...   \n2200  Serial drama ini dibintangi Shota Matsuda, Kat...   \n\n                                             hypothesis  label  \n0                 Sungai Genil tidak mengaliri Granada.      2  \n1     \"Titanic-The Promise of Modernity\" adalah pame...      0  \n2     Hak Asasi Manusia (HAM) sangat penting untuk o...      1  \n3     Terdapat 2 grup musisi untuk genre pop pada ko...      1  \n4                             Ketiak pejabat sipil bau.      1  \n...                                                 ...    ...  \n2196        Mariah memeriksakan dirinya ke rumah sakit.      0  \n2197  Tetesan air yang terserap ke dalam tanah berba...      1  \n2198         Banyak kegiatan asyik selain berpetualang.      1  \n2199  Purwokerto Utara adalah sebuah kecamatan di Ka...      1  \n2200     Serial drama ini tidak dibintangi Yuki Uchida.      2  \n\n[2201 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Santa Fe adalah sebuah kotamadya di Vega de Gr...</td>\n      <td>Sungai Genil tidak mengaliri Granada.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pameran bertajuk \"Titanic—The Promise of Moder...</td>\n      <td>\"Titanic-The Promise of Modernity\" adalah pame...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Misalnya, dengan dicantumkannya Hak Asasi Manu...</td>\n      <td>Hak Asasi Manusia (HAM) sangat penting untuk o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Konser bertajuk Cross Genre Music ini adalah g...</td>\n      <td>Terdapat 2 grup musisi untuk genre pop pada ko...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Pakaian formal yang dikenakan pejabat sipil (b...</td>\n      <td>Ketiak pejabat sipil bau.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2196</th>\n      <td>Mariah segera memeriksakan dirinya ke rumah sa...</td>\n      <td>Mariah memeriksakan dirinya ke rumah sakit.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2197</th>\n      <td>Selama curah hujan, tetesan air menyerap dan m...</td>\n      <td>Tetesan air yang terserap ke dalam tanah berba...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2198</th>\n      <td>Berpetualang bersama teman di Gunung Batu Jong...</td>\n      <td>Banyak kegiatan asyik selain berpetualang.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2199</th>\n      <td>Purwokerto Selatan adalah sebuah kecamatan di ...</td>\n      <td>Purwokerto Utara adalah sebuah kecamatan di Ka...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2200</th>\n      <td>Serial drama ini dibintangi Shota Matsuda, Kat...</td>\n      <td>Serial drama ini tidak dibintangi Yuki Uchida.</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>2201 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Count per class test:\") \nprint(df_test_t['label'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.962474Z","iopub.execute_input":"2023-07-17T19:05:09.962787Z","iopub.status.idle":"2023-07-17T19:05:09.971121Z","shell.execute_reply.started":"2023-07-17T19:05:09.962760Z","shell.execute_reply":"2023-07-17T19:05:09.969854Z"},"trusted":true},"execution_count":278,"outputs":[{"name":"stdout","text":"Count per class test:\n0    808\n2    764\n1    629\nName: label, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"tokenizer = XLMRobertaTokenizer.from_pretrained(TOKENIZER_TYPE)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:09.973431Z","iopub.execute_input":"2023-07-17T19:05:09.974522Z","iopub.status.idle":"2023-07-17T19:05:10.867940Z","shell.execute_reply.started":"2023-07-17T19:05:09.974478Z","shell.execute_reply":"2023-07-17T19:05:10.866791Z"},"trusted":true},"execution_count":279,"outputs":[]},{"cell_type":"code","source":"class CompDataset(Dataset):\n    def __init__(self, df_teacher, df_student):\n        self.df_data_teacher = df_teacher\n        self.df_data_student = df_student\n        \n    def __getitem__(self, index):\n        # Teacher\n        sentence_teacher_1 = self.df_data_teacher.loc[index, 'premise']\n        sentence_teacher_2 = self.df_data_teacher.loc[index, 'hypothesis']\n        \n        encoded_dict_teacher = tokenizer.encode_plus(\n            sentence_teacher_1,\n            sentence_teacher_2,\n            add_special_tokens = True,\n            max_length = MAX_LEN,\n            truncation='longest_first',\n            padding = 'max_length',\n            return_attention_mask = True,\n            return_tensors = 'pt'\n        )\n        \n        padded_token_list_teacher = encoded_dict_teacher['input_ids'][0]\n        att_mask_teacher = encoded_dict_teacher['attention_mask'][0]\n        \n        target_teacher = torch.tensor([self.df_data_teacher.loc[index, 'label']])\n        lt_target_teacher = torch.LongTensor(target_teacher)\n        onehot_encoded_lbl_teacher = F.one_hot(lt_target_teacher, num_classes=3) # 3 classes: entails, neutral, contradict\n        \n        # Student\n        sentence_student_1 = self.df_data_student.loc[index, 'premise']\n        sentence_student_2 = self.df_data_student.loc[index, 'hypothesis']\n        \n        encoded_dict_student = tokenizer.encode_plus(\n            sentence_student_1,\n            sentence_student_2,\n            add_special_tokens = True,\n            max_length = MAX_LEN,\n            truncation='longest_first',\n            padding = 'max_length',\n            return_attention_mask = True,\n            return_tensors = 'pt'\n        )\n        \n        padded_token_list_student = encoded_dict_student['input_ids'][0]\n        att_mask_student = encoded_dict_student['attention_mask'][0]\n        \n        target_student = torch.tensor([self.df_data_student.loc[index, 'label']])\n        lt_target_student = torch.LongTensor(target_student)\n        onehot_encoded_lbl_student = F.one_hot(lt_target_student, num_classes=3) # 3 classes: entails, neutral, contradict\n        \n        output = {\n            \"input_ids_teacher\": padded_token_list_teacher, \n            \"attention_mask_teacher\": att_mask_teacher,\n            \"lbl_teacher\": onehot_encoded_lbl_teacher,\n            \"input_ids_student\": padded_token_list_student, \n            \"attention_mask_student\": att_mask_student,\n            \"lbl_student\": onehot_encoded_lbl_student\n        }\n        \n        return output\n    \n    def __len__(self):\n        return len(self.df_data_teacher)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:10.869602Z","iopub.execute_input":"2023-07-17T19:05:10.869991Z","iopub.status.idle":"2023-07-17T19:05:10.883435Z","shell.execute_reply.started":"2023-07-17T19:05:10.869955Z","shell.execute_reply":"2023-07-17T19:05:10.881775Z"},"trusted":true},"execution_count":280,"outputs":[]},{"cell_type":"code","source":"train_data_cmp = CompDataset(df_train_t, df_train_student)\nvalid_data_cmp = CompDataset(df_valid_t, df_valid_student)\ntest_data_cmp = CompDataset(df_test_t, df_test_student)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:10.885325Z","iopub.execute_input":"2023-07-17T19:05:10.886081Z","iopub.status.idle":"2023-07-17T19:05:10.900169Z","shell.execute_reply.started":"2023-07-17T19:05:10.886044Z","shell.execute_reply":"2023-07-17T19:05:10.899163Z"},"trusted":true},"execution_count":281,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_data_cmp, batch_size = BATCH_SIZE)\nvalid_dataloader = DataLoader(valid_data_cmp, batch_size = BATCH_SIZE)\ntest_dataloader = DataLoader(test_data_cmp, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:10.901730Z","iopub.execute_input":"2023-07-17T19:05:10.902465Z","iopub.status.idle":"2023-07-17T19:05:10.914276Z","shell.execute_reply.started":"2023-07-17T19:05:10.902411Z","shell.execute_reply":"2023-07-17T19:05:10.913159Z"},"trusted":true},"execution_count":282,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"markdown","source":"Transfer Learning model as per Bandyopadhyay, D., et al (2022) paper, but using XLMR instead of mBERT","metadata":{}},{"cell_type":"code","source":"class TransferLearningPaper(PreTrainedModel):\n    def __init__(self, config, lambda_kld, learningrate_student, batchnorm_epsilon = 1e-5):\n        super(TransferLearningPaper, self).__init__(config)\n        \n        self.xlmr_model_teacher = XLMRobertaModel.from_pretrained(\n            MODEL_TEACHER_TYPE, # using pretrained mBERT in INA language\n            num_labels = 3,\n            output_hidden_states=True\n        )\n        \n        # Freeze teacher mBERT parameters\n        for params_teacher in self.xlmr_model_teacher.parameters():\n            params_teacher.requires_grad = False\n    \n        self.xlmr_model_student = XLMRobertaModel.from_pretrained(\n            MBERT_TYPE,\n            num_labels = 3,\n            output_hidden_states=True\n        )\n        \n        # Unfreeze student mBERT parameters\n        for params_student in self.xlmr_model_student.parameters():\n            params_student.requires_grad = True\n        \n        self.optimizer_student = AdamW(\n            self.xlmr_model_student.parameters(), \n            lr=learningrate_student\n        )\n        \n        self.linear = nn.Linear(config.hidden_size, 3)  # Linear layer\n        self.batchnorm = nn.BatchNorm1d(config.hidden_size, eps=batchnorm_epsilon)\n        self.softmax = nn.Softmax(dim=1)  # Softmax activation\n        \n        self.cross_entropy = nn.CrossEntropyLoss()\n        self.kld = nn.KLDivLoss(reduction='batchmean')\n        \n        # Initialize the weights of the linear layer\n        self.linear.weight.data.normal_(mean=0.0, std=0.02)\n        self.linear.bias.data.zero_()\n        \n        self.lambda_kld = lambda_kld\n    \n    def forward(self, input_ids_teacher, attention_mask_teacher, lbl_teacher, input_ids_student, attention_mask_student, lbl_student):\n        # the label is already one-hot encoded \n        self.xlmr_model_teacher.eval()\n        self.xlmr_model_student.eval()\n        \n        lbl_teacher = lbl_teacher[:, 0, :]\n        lbl_student = lbl_student[:, 0, :]\n        \n        with torch.no_grad():\n            # Taking CLS token out of XLMR last hidden state\n            outputs_teacher = self.xlmr_model_teacher(\n                input_ids=input_ids_teacher, \n                attention_mask=attention_mask_teacher #, \n                #labels=lbl_teacher\n            )\n        \n            # take CLS token of the last hidden state\n            pooled_output_teacher = outputs_teacher.last_hidden_state[:, 0, :]\n        \n        # taking CLS token out of the student data without deleting the gradient\n        outputs_student = self.xlmr_model_student(\n            input_ids=input_ids_student, \n            attention_mask=attention_mask_student #, \n            #labels=lbl_student\n        )\n        \n        pooled_output_student = outputs_student.last_hidden_state[:, 0, :]\n        \n        # FFNN\n        batchnormed_logits = self.batchnorm(pooled_output_student)\n        linear_output = self.linear(batchnormed_logits) # the output's logits\n        softmax_linear_output = F.log_softmax(linear_output, dim=1)\n        \n        lbl_student = lbl_student.float()\n        softmax_linear_output = softmax_linear_output.float()\n        \n        # Loss Computation\n        cross_entropy_loss = self.cross_entropy(softmax_linear_output, lbl_student)\n        total_kld = self.kld(F.log_softmax(pooled_output_student, dim=1), F.softmax(pooled_output_teacher, dim=1))\n        joint_loss = cross_entropy_loss + (self.lambda_kld * total_kld )\n        \n        return {\"loss\": joint_loss, \"logits\": softmax_linear_output}\n    \n    def clear_grad(self):\n        self.xlmr_model_student.train()\n        self.optimizer_student.zero_grad()\n    \n    def backpro_compute(self, loss):\n        loss.backward()\n        \n    def update_std_weights_and_clear_grad(self):\n        self.optimizer_student.step()\n        self.optimizer_student.zero_grad()\n    \n    def update_std_weights(self):\n        self.optimizer_student.step()\n    \n    def update_param_student_model(self, loss):\n        # Doing customized backpropagation for student's model\n        self.xlmr_model_student.train()\n        \n        self.optimizer_student.zero_grad()\n        loss.backward()\n        self.optimizer_student.step()\n        \n    def upload_to_huggingface(self):\n        self.xlmr_model_student.push_to_hub(HF_MODEL_NAME)\n        tokenizer.push_to_hub(HF_MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:10.916004Z","iopub.execute_input":"2023-07-17T19:05:10.916643Z","iopub.status.idle":"2023-07-17T19:05:10.938021Z","shell.execute_reply.started":"2023-07-17T19:05:10.916604Z","shell.execute_reply":"2023-07-17T19:05:10.936756Z"},"trusted":true},"execution_count":283,"outputs":[]},{"cell_type":"code","source":"config = PretrainedConfig(\n    problem_type = \"single_label_classification\",\n    id2label = {\n        \"0\": \"ENTAIL\",\n        \"1\": \"NEUTRAL\",\n        \"2\": \"CONTRADICTION\"\n    },\n    label2id = {\n        \"ENTAIL\": 0,\n        \"NEUTRAL\": 1,\n        \"CONTRADICTION\": 2\n    },\n    num_labels = 3,\n    hidden_size = 768,\n    name_or_path = \"indojavanesenli-transfer-learning\",\n    finetuning_task = \"indonesian-javanese natural language inference\"\n)\nprint(config)\ntransferlearning_model = TransferLearningPaper(\n    config = config,\n    lambda_kld = LAMBDA_KLD, # antara 0.01-0.5\n    learningrate_student = STUDENT_LRATE,\n    batchnorm_epsilon = BATCH_NORM_EPSILON\n)\ntransferlearning_model = transferlearning_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:10.940365Z","iopub.execute_input":"2023-07-17T19:05:10.941564Z","iopub.status.idle":"2023-07-17T19:05:26.660171Z","shell.execute_reply.started":"2023-07-17T19:05:10.941522Z","shell.execute_reply":"2023-07-17T19:05:26.657092Z"},"trusted":true},"execution_count":284,"outputs":[{"name":"stdout","text":"PretrainedConfig {\n  \"_name_or_path\": \"indojavanesenli-transfer-learning\",\n  \"finetuning_task\": \"indonesian-javanese natural language inference\",\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"ENTAIL\",\n    \"1\": \"NEUTRAL\",\n    \"2\": \"CONTRADICTION\"\n  },\n  \"label2id\": {\n    \"CONTRADICTION\": 2,\n    \"ENTAIL\": 0,\n    \"NEUTRAL\": 1\n  },\n  \"problem_type\": \"single_label_classification\",\n  \"transformers_version\": \"4.30.2\"\n}\n\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at jalaluddin94/xlmr-nli-indoindo were not used when initializing XLMRobertaModel: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLMRobertaModel were not initialized from the model checkpoint at jalaluddin94/xlmr-nli-indoindo and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m25\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m22 \u001b[0m\u001b[2m│   \u001b[0mlearningrate_student = STUDENT_LRATE,                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2m│   \u001b[0mbatchnorm_epsilon = BATCH_NORM_EPSILON                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m24 \u001b[0m)                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m25 transferlearning_model = transferlearning_model.to(device)                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m26 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mmodeling_utils.py\u001b[0m:\u001b[94m1902\u001b[0m in \u001b[92mto\u001b[0m                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1899 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1900 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96msuper\u001b[0m().to(*args, **kwargs)                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1901 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1902 \u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mhalf\u001b[0m(\u001b[96mself\u001b[0m, *args):                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1903 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Checks if the model has been loaded in 8-bit\u001b[0m                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1904 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mgetattr\u001b[0m(\u001b[96mself\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mis_quantized\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mFalse\u001b[0m):                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1905 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1145\u001b[0m in \u001b[92mto\u001b[0m                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1142 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mnon_blocking, memory_format=convert_to_format)                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1143 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m t.to(device, dtype \u001b[94mif\u001b[0m t.is_floating_point() \u001b[95mor\u001b[0m t.is_complex() \u001b[94melse\u001b[0m \u001b[94mNo\u001b[0m  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1144 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1145 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._apply(convert)                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1146 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1147 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mregister_full_backward_pre_hook\u001b[0m(                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1148 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m,                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m797\u001b[0m in \u001b[92m_apply\u001b[0m                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 794 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 795 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 796 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 797 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 798 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 799 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 800 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m797\u001b[0m in \u001b[92m_apply\u001b[0m                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 794 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 795 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 796 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 797 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 798 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 799 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 800 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m797\u001b[0m in \u001b[92m_apply\u001b[0m                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 794 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 795 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 796 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 797 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 798 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 799 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 800 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m820\u001b[0m in \u001b[92m_apply\u001b[0m                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 817 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# track autograd history of `param_applied`, so we have to use\u001b[0m                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 818 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# `with torch.no_grad():`\u001b[0m                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 819 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 820 \u001b[2m│   │   │   │   \u001b[0mparam_applied = fn(param)                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 821 \u001b[0m\u001b[2m│   │   │   \u001b[0mshould_use_set_data = compute_should_use_set_data(param, param_applied)       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 822 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m should_use_set_data:                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 823 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mparam.data = param_applied                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1143\u001b[0m in \u001b[92mconvert\u001b[0m               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1140 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m convert_to_format \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m t.dim() \u001b[95min\u001b[0m (\u001b[94m4\u001b[0m, \u001b[94m5\u001b[0m):                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1141 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m t.to(device, dtype \u001b[94mif\u001b[0m t.is_floating_point() \u001b[95mor\u001b[0m t.is_complex() \u001b[94mels\u001b[0m  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1142 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mnon_blocking, memory_format=convert_to_format)                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1143 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m t.to(device, dtype \u001b[94mif\u001b[0m t.is_floating_point() \u001b[95mor\u001b[0m t.is_complex() \u001b[94melse\u001b[0m \u001b[94mNo\u001b[0m  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1144 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1145 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._apply(convert)                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1146 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m734.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m15.90\u001b[0m GiB total capacity; \u001b[1;36m13.51\u001b[0m GiB \nalready allocated; \u001b[1;36m371.75\u001b[0m MiB free; \u001b[1;36m14.65\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated \nmemory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \nPYTORCH_CUDA_ALLOC_CONF\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">25</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>learningrate_student = STUDENT_LRATE,                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>batchnorm_epsilon = BATCH_NORM_EPSILON                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24 </span>)                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>25 transferlearning_model = transferlearning_model.to(device)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1902</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1899 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1900 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().to(*args, **kwargs)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1901 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1902 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">half</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args):                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1903 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Checks if the model has been loaded in 8-bit</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1904 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"is_quantized\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1905 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1145</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1142 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>non_blocking, memory_format=convert_to_format)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1143 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">No</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1145 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._apply(convert)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1146 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1147 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">register_full_backward_pre_hook</span>(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1148 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>,                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">797</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 794 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 795 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 796 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 797 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 798 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 799 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 800 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">797</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 794 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 795 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 796 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 797 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 798 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 799 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 800 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">797</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 794 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 795 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 796 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 797 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 798 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 799 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 800 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">820</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 817 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># track autograd history of `param_applied`, so we have to use</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 818 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># `with torch.no_grad():`</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 819 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 820 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>param_applied = fn(param)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 821 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>should_use_set_data = compute_should_use_set_data(param, param_applied)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 822 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> should_use_set_data:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 823 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>param.data = param_applied                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1143</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">convert</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1140 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> convert_to_format <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> t.dim() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>):                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">els</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1142 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>non_blocking, memory_format=convert_to_format)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1143 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">No</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1145 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._apply(convert)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1146 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">734.00</span> MiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.90</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.51</span> GiB \nalready allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">371.75</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.65</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated \nmemory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \nPYTORCH_CUDA_ALLOC_CONF\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:26.661955Z","iopub.status.idle":"2023-07-17T19:05:26.662509Z","shell.execute_reply.started":"2023-07-17T19:05:26.662214Z","shell.execute_reply":"2023-07-17T19:05:26.662240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function to compute metrics","metadata":{}},{"cell_type":"code","source":"def compute_metrics(p):\n    pred, labels = p\n    pred = np.argmax(pred, axis=1)\n    labels = np.argmax(labels[:,0,:], axis=1)\n\n    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n    recall = recall_score(y_true=labels, y_pred=pred, average='micro')\n    precision = precision_score(y_true=labels, y_pred=pred, average='micro')\n    f1 = f1_score(y_true=labels, y_pred=pred, average='weighted')\n\n    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1_score\": f1}","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:26.664780Z","iopub.status.idle":"2023-07-17T19:05:26.665321Z","shell.execute_reply.started":"2023-07-17T19:05:26.665032Z","shell.execute_reply":"2023-07-17T19:05:26.665058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Manual training function","metadata":{}},{"cell_type":"code","source":"def train(the_model, train_data, pgb):\n    the_model.train()\n    \n    batch_loss = 0\n    \n    for batch, data in enumerate(train_data):\n        # Clear accumulated gradients\n        the_model.clear_grad()\n        \n        input_ids_teacher = data[\"input_ids_teacher\"].to(device)\n        attention_mask_teacher = data[\"attention_mask_teacher\"].to(device)\n        lbl_teacher = data[\"lbl_teacher\"].to(device)\n        input_ids_student = data[\"input_ids_student\"].to(device)\n        attention_mask_student = data[\"attention_mask_student\"].to(device)\n        lbl_student = data[\"lbl_student\"].to(device)\n        \n        output = the_model(\n            input_ids_teacher = input_ids_teacher, \n            attention_mask_teacher = attention_mask_teacher,\n            lbl_teacher = lbl_teacher,\n            input_ids_student = input_ids_student, \n            attention_mask_student = attention_mask_student, \n            lbl_student = lbl_student\n        )\n        \n        loss_model = output[\"loss\"]\n        batch_loss += loss_model\n        \n        # Backpropagation\n        # the_model.update_param_student_model(loss_model) # uncomment to use ordinary backpro\n        ## now using gradient accumulation technique\n        the_model.backpro_compute(loss_model) # backward pass and gradient accumulation\n        \n        # Accumulate gradients for the desired number of mini-batches\n        if(batch+1) % BATCH_SIZE == 0:\n            # update weights\n            the_model.update_std_weights_and_clear_grad()\n        \n        pgb.update(1 / len(train_data))\n    \n    # Make sure to update the weights for any remaining accumulated gradients\n    if (batch+1) % BATCH_SIZE != 0:\n        the_model.update_std_weights()\n        \n    training_loss = batch_loss / BATCH_SIZE\n#     wandb.log({\"train/loss\": training_loss})\n    \n    return training_loss","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:26.667579Z","iopub.status.idle":"2023-07-17T19:05:26.668151Z","shell.execute_reply.started":"2023-07-17T19:05:26.667842Z","shell.execute_reply":"2023-07-17T19:05:26.667868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(the_model, valid_data):\n    the_model.eval()\n    \n    batch_loss = 0\n    \n    eval_f1 = []\n    eval_accuracy = []\n    eval_precision = []\n    eval_recall = []\n    \n    with torch.no_grad():\n        for batch, data in enumerate(valid_data):\n            input_ids_teacher = data[\"input_ids_teacher\"].to(device)\n            attention_mask_teacher = data[\"attention_mask_teacher\"].to(device)\n            lbl_teacher = data[\"lbl_teacher\"].to(device)\n            input_ids_student = data[\"input_ids_student\"].to(device)\n            attention_mask_student = data[\"attention_mask_student\"].to(device)\n            lbl_student = data[\"lbl_student\"].to(device)\n\n            output = the_model(\n                input_ids_teacher = input_ids_teacher, \n                attention_mask_teacher = attention_mask_teacher, \n                lbl_teacher = lbl_teacher,\n                input_ids_student = input_ids_student, \n                attention_mask_student = attention_mask_student,\n                lbl_student = lbl_student\n            )\n\n            logits = output[\"logits\"].cpu().detach().numpy()\n            packed_val = logits, lbl_student.cpu().detach().numpy()\n            metrics = compute_metrics(packed_val)\n            \n            eval_f1.append(metrics[\"f1_score\"])\n            eval_accuracy.append(metrics[\"accuracy\"])\n            eval_precision.append(metrics[\"precision\"])\n            eval_recall.append(metrics[\"recall\"])\n            \n            loss_model = output[\"loss\"]\n            batch_loss += loss_model\n\n            # t.update(1 / len(valid_data))\n    \n        eval_loss = batch_loss / BATCH_SIZE\n#         wandb.log({\n#             \"eval/loss\": eval_loss, \n#             \"eval/f1_score\": np.average(eval_f1), \n#             \"eval/accuracy\": np.average(eval_accuracy),\n#             \"eval/precision\": np.average(eval_precision),\n#             \"eval/recall\": np.average(eval_recall)\n#         })\n    \n    out_metrics = {\n        \"eval/loss\": eval_loss, \n        \"eval/f1_score\": np.average(eval_f1), \n        \"eval/accuracy\": np.average(eval_accuracy),\n        \"eval/precision\": np.average(eval_precision),\n        \"eval/recall\": np.average(eval_recall)\n    }\n    \n    return eval_loss, out_metrics","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:26.671902Z","iopub.status.idle":"2023-07-17T19:05:26.672436Z","shell.execute_reply.started":"2023-07-17T19:05:26.672142Z","shell.execute_reply":"2023-07-17T19:05:26.672167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training_sequence(the_model, train_data, valid_data, epochs):\n    track_train_loss = []\n    track_val_loss = []\n    \n    pbar_format = \"{l_bar}{bar} | Epoch: {n:.2f}/{total_fmt} [{elapsed}<{remaining}]\"\n    with tqdm(total=epochs, colour=\"blue\", leave=True, position=0, bar_format=pbar_format) as t:\n        for ep in range(epochs):\n            training_loss = train(the_model, train_data, t)\n            t.set_description(f\"Evaluating... Train loss: {training_loss:.3f}\")\n            valid_loss, _ = validate(the_model, valid_data)\n\n            track_train_loss.append(training_loss)\n            track_val_loss.append(valid_loss)\n\n            t.set_description(f\"Train loss: {training_loss:.3f} Valid loss: {valid_loss:.3f}\")\n\n            if valid_loss < min(track_val_loss) or ep + 1 == 1:\n                the_model.save_pretrained(\n                    save_directory = MODEL_PATH + \"indojavanesenli-transfer-learning\"\n                )\n\n#             wandb.log({\n#                 \"train_loss/epoch\": training_loss,\n#                 \"validation_loss/epoch\": valid_loss\n#             })\n        \n    return {\n        \"training_loss\": track_train_loss,\n        \"validation_loss\": track_val_loss\n    }","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:26.674596Z","iopub.status.idle":"2023-07-17T19:05:26.675156Z","shell.execute_reply.started":"2023-07-17T19:05:26.674885Z","shell.execute_reply":"2023-07-17T19:05:26.674912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_result = training_sequence(transferlearning_model, train_dataloader, valid_dataloader, NUM_EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:26.677231Z","iopub.status.idle":"2023-07-17T19:05:26.677764Z","shell.execute_reply.started":"2023-07-17T19:05:26.677480Z","shell.execute_reply":"2023-07-17T19:05:26.677503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2023-07-17T19:05:26.682656Z","iopub.status.idle":"2023-07-17T19:05:26.683192Z","shell.execute_reply.started":"2023-07-17T19:05:26.682921Z","shell.execute_reply":"2023-07-17T19:05:26.682948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transferlearning_model.upload_to_huggingface()","metadata":{},"execution_count":null,"outputs":[]}]}